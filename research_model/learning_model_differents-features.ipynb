{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,MaxAbsScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from sklearn.metrics import r2_score,mean_squared_error, mean_absolute_error\n",
    "\n",
    "from sklearn.metrics import precision_score,f1_score\n",
    "import xgboost as xgb\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier,DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, RidgeClassifier, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier,GradientBoostingRegressor\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, VotingClassifier \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./all-dataset-and-calculate-BMI-and-remove-height-weight.csv')\n",
    "\n",
    "df['cholesterol'] = df['cholesterol'].replace({\n",
    "    1: round(random.uniform(1.0, 5.17),2),\n",
    "    2: round(random.uniform(5.17, 6.18),2),\n",
    "    3: round(random.uniform(6.21, 7.21),2)\n",
    "})\n",
    "\n",
    "df['gluc'] = df['gluc'].replace({\n",
    "    1: round(random.uniform(3.5,5.7),2),\n",
    "    2: round(random.uniform(5.7,6.9),2),\n",
    "    3: round(random.uniform(7.0,10.4)),\n",
    "})\n",
    "\n",
    "df['pulse_pressure'] = df['ap_hi'] - df['ap_lo']\n",
    "df['pulse_pressure_index'] = df['pulse_pressure'] / df['ap_hi']\n",
    "df = df.drop('pulse_pressure',axis=1)\n",
    "df\n",
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n",
    "df_ensemble = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pulse_pressure_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>2.33</td>\n",
       "      <td>4.16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>6.33</td>\n",
       "      <td>4.16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>6.33</td>\n",
       "      <td>4.16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>2.33</td>\n",
       "      <td>4.16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>2.33</td>\n",
       "      <td>4.16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68970</th>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>2.33</td>\n",
       "      <td>4.16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68971</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>5.43</td>\n",
       "      <td>6.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68972</th>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>180</td>\n",
       "      <td>90</td>\n",
       "      <td>6.33</td>\n",
       "      <td>4.16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68973</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>135</td>\n",
       "      <td>80</td>\n",
       "      <td>2.33</td>\n",
       "      <td>6.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.407407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68974</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>5.43</td>\n",
       "      <td>4.16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68975 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  gender  ap_hi  ap_lo  cholesterol  gluc  smoke  alco  active  \\\n",
       "0       50       2    110     80         2.33  4.16      0     0       1   \n",
       "1       55       1    140     90         6.33  4.16      0     0       1   \n",
       "2       51       1    130     70         6.33  4.16      0     0       0   \n",
       "3       48       2    150    100         2.33  4.16      0     0       1   \n",
       "4       47       1    100     60         2.33  4.16      0     0       0   \n",
       "...    ...     ...    ...    ...          ...   ...    ...   ...     ...   \n",
       "68970   52       2    120     80         2.33  4.16      1     0       1   \n",
       "68971   61       1    140     90         5.43  6.07      0     0       1   \n",
       "68972   52       2    180     90         6.33  4.16      0     1       0   \n",
       "68973   61       1    135     80         2.33  6.07      0     0       0   \n",
       "68974   56       1    120     80         5.43  4.16      0     0       1   \n",
       "\n",
       "       cardio   bmi  pulse_pressure_index  \n",
       "0           0  22.0              0.272727  \n",
       "1           1  35.0              0.357143  \n",
       "2           1  24.0              0.461538  \n",
       "3           1  29.0              0.333333  \n",
       "4           0  23.0              0.400000  \n",
       "...       ...   ...                   ...  \n",
       "68970       0  27.0              0.333333  \n",
       "68971       1  50.0              0.357143  \n",
       "68972       1  31.0              0.500000  \n",
       "68973       1  27.0              0.407407  \n",
       "68974       0  25.0              0.333333  \n",
       "\n",
       "[68975 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_plot(data):\n",
    "    plt.figure(figsize=(8,8))\n",
    "    sns.heatmap(data.corr(),cmap='coolwarm',annot=True)\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('cardio',axis=1)\n",
    "y = df['cardio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(       age  gender  ap_hi  ap_lo  cholesterol  gluc  smoke  alco  active  \\\n",
       " 0       50       2    110     80         3.19  3.84      0     0       1   \n",
       " 1       55       1    140     90         6.58  3.84      0     0       1   \n",
       " 2       51       1    130     70         6.58  3.84      0     0       0   \n",
       " 3       48       2    150    100         3.19  3.84      0     0       1   \n",
       " 4       47       1    100     60         3.19  3.84      0     0       0   \n",
       " ...    ...     ...    ...    ...          ...   ...    ...   ...     ...   \n",
       " 68970   52       2    120     80         3.19  3.84      1     0       1   \n",
       " 68971   61       1    140     90         5.72  6.41      0     0       1   \n",
       " 68972   52       2    180     90         6.58  3.84      0     1       0   \n",
       " 68973   61       1    135     80         3.19  6.41      0     0       0   \n",
       " 68974   56       1    120     80         5.72  3.84      0     0       1   \n",
       " \n",
       "         bmi  pulse_pressure_index  \n",
       " 0      22.0              0.272727  \n",
       " 1      35.0              0.357143  \n",
       " 2      24.0              0.461538  \n",
       " 3      29.0              0.333333  \n",
       " 4      23.0              0.400000  \n",
       " ...     ...                   ...  \n",
       " 68970  27.0              0.333333  \n",
       " 68971  50.0              0.357143  \n",
       " 68972  31.0              0.500000  \n",
       " 68973  27.0              0.407407  \n",
       " 68974  25.0              0.333333  \n",
       " \n",
       " [68975 rows x 11 columns],\n",
       " 0        0\n",
       " 1        1\n",
       " 2        1\n",
       " 3        1\n",
       " 4        0\n",
       "         ..\n",
       " 68970    0\n",
       " 68971    1\n",
       " 68972    1\n",
       " 68973    1\n",
       " 68974    0\n",
       " Name: cardio, Length: 68975, dtype: int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((62077, 11), (6898, 11), (62077,), (6898,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.1,random_state=0)\n",
    "\n",
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Робимо нормалізацію для датасету та навчаємо модель та обираємо кращу датасет та нормалізацію"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train= scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=20000, solver='liblinear', random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"XGBoost\": xgb.XGBClassifier(n_estimators=100, max_depth=5, learning_rate=0.1, random_state=42),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"MLP Neural Network\": MLPClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Навчаємо модель Logistic Regression\n",
      "Accuracy: 0.73\n",
      "Precision: 0.76\n",
      "F1-score: 0.71\n",
      "Навчаємо модель Decision Tree\n",
      "Accuracy: 0.66\n",
      "Precision: 0.7\n",
      "F1-score: 0.64\n",
      "Навчаємо модель Random Forest\n",
      "Accuracy: 0.71\n",
      "Precision: 0.72\n",
      "F1-score: 0.7\n",
      "Навчаємо модель KNN\n",
      "\n",
      "\n",
      "\n",
      "Accuracy: 0.7\n",
      "Precision: 0.72\n",
      "F1-score: 0.7\n",
      "Навчаємо модель Gradient Boosting\n",
      "Accuracy: 0.74\n",
      "Precision: 0.77\n",
      "F1-score: 0.73\n",
      "Навчаємо модель XGBoost\n",
      "Accuracy: 0.74\n",
      "Precision: 0.77\n",
      "F1-score: 0.73\n",
      "Навчаємо модель AdaBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Heart-Failure\\env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.73\n",
      "Precision: 0.78\n",
      "F1-score: 0.71\n",
      "Навчаємо модель Naive Bayes\n",
      "Accuracy: 0.7\n",
      "Precision: 0.75\n",
      "F1-score: 0.68\n",
      "Навчаємо модель MLP Neural Network\n",
      "Accuracy: 0.74\n",
      "Precision: 0.77\n",
      "F1-score: 0.73\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for name, model in models.items():\n",
    "    print(f'Навчаємо модель {name}')\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    # print(f\"Shape of y_pred_all: {y_pred_all.shape}\")\n",
    "    # print(f\"Shape of df_copy: {df_copy.shape}\")\n",
    "    if name == \"KNN\":\n",
    "        print(\"\\n\\n\")\n",
    "    print(f'Accuracy: {np.round(accuracy_score(y_test, y_pred_test), 2)}')\n",
    "    print(f'Precision: {np.round(precision_score(y_test,y_pred_test),2)}')\n",
    "    print(f'F1-score: {np.round(f1_score(y_test,y_pred_test),2)}')\n",
    "\n",
    "# print('\\nUpdate dataset with added features')\n",
    "\n",
    "# df.to_excel('updated_dataset.xlsx', index=False)\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Навчаємо модель Logistic Regression\n",
      "Accuracy: 0.73\n",
      "Precision: 0.76\n",
      "F1-score: 0.71\n",
      "Навчаємо модель KNN\n",
      "Accuracy: 0.7\n",
      "Precision: 0.72\n",
      "F1-score: 0.7\n",
      "Навчаємо модель Naive Bayes\n",
      "Accuracy: 0.7\n",
      "Precision: 0.75\n",
      "F1-score: 0.68\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f'Навчаємо модель {name}')\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "\n",
    "    y_pred_all = np.concatenate([y_pred_train,y_pred_test])\n",
    "    if len(y_pred_all) == len(df_ensemble):\n",
    "        df_ensemble[f\"{name}_prediction\"] = y_pred_all\n",
    "    else:\n",
    "        print(\"Error\")\n",
    "\n",
    "\n",
    "    print(f'Accuracy: {np.round(accuracy_score(y_test, y_pred_test), 2)}')\n",
    "    print(f'Precision: {np.round(precision_score(y_test,y_pred_test),2)}')\n",
    "    print(f'F1-score: {np.round(f1_score(y_test,y_pred_test),2)}')\n",
    "\n",
    "df_ensemble.to_excel('updated_dataset_with_predictions.xlsx', index=False)\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Heart-Failure\\env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for name,model in models.items():\n",
    "\n",
    "    model.fit(X_train[:300],y_train[:300])\n",
    "\n",
    "    predicted = model.predict(X_test[:300])\n",
    "    residuals = y_test[:300] - predicted\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=list(range(len(y_test[:300]))),\n",
    "        y=residuals,\n",
    "        mode='lines+markers',\n",
    "        name=name\n",
    "    ))\n",
    "\n",
    "fig.add_hline(y=0,line_dash=\"dash\",line_color=\"black\",\n",
    "                annotation_text=\"Zero Error Line\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Residuals for Validation Set (Interactive)\",\n",
    "    xaxis_title=\"Index\",\n",
    "    yaxis_title=\"Residuals (True - Predicted)\",\n",
    "    template=\"plotly_white\",\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig.write_html(\"residuals_plot.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Спробуємо створити власний ансабиль використовуючи фітчі, якими є передбчення моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ensemble = df_ensemble.drop('cardio',axis=1)\n",
    "y_ensemble = df_ensemble['cardio']\n",
    "\n",
    "X_train_ensemble,X_test_ensemble,y_train_ensemble,y_test_ensemble = train_test_split(X_ensemble,y_ensemble,train_size=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Навчаємо модель Gradient Boosting\n",
      "Accuracy on test set: 0.73\n",
      "Precision: 0.75\n",
      "F1-score: 0.68\n",
      "Навчаємо модель XGBoost\n",
      "Accuracy on test set: 0.73\n",
      "Precision: 0.75\n",
      "F1-score: 0.68\n",
      "Навчаємо модель MLP Neural Network\n",
      "Accuracy on test set: 0.71\n",
      "Precision: 0.75\n",
      "F1-score: 0.68\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for name, model in models.items():\n",
    "    print(f'Навчаємо модель {name}')\n",
    "\n",
    "    model.fit(X_train_ensemble,y_train_ensemble)\n",
    "\n",
    "    y_pred = model.predict(X_test_ensemble)\n",
    "\n",
    "    # print(f\"Shape of y_pred_all: {y_pred_all.shape}\")\n",
    "    # print(f\"Shape of df_copy: {df_copy.shape}\")\n",
    "\n",
    "    print(f'Accuracy on test set: {np.round(accuracy_score(y_test_ensemble, y_pred), 2)}')\n",
    "    print(f'Precision: {np.round(precision_score(y_test,y_pred_test),2)}')\n",
    "    print(f'F1-score: {np.round(f1_score(y_test,y_pred_test),2)}')\n",
    "\n",
    "# print('\\nUpdate dataset with added features')\n",
    "\n",
    "# df_ensemble.to_excel('updated_dataset_ensemble.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for stacking model: 0.74\n",
      "Precision: 0.77\n",
      "F1-score: 0.73\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "base_models = [\n",
    "    ('mlp',MLPClassifier()),\n",
    "    ('grad',GradientBoostingClassifier())\n",
    "]\n",
    "\n",
    "stack_model = StackingClassifier(\n",
    "    estimators=base_models,\n",
    "    final_estimator=LogisticRegression(),\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "stack_model.fit(X_train,y_train)\n",
    "\n",
    "y_pred_test = stack_model.predict(X_test)\n",
    "\n",
    "print(f'Accuracy for stacking model: {np.round(accuracy_score(y_test,y_pred_test),2)}')\n",
    "print(f'Precision: {np.round(precision_score(y_test,y_pred_test),2)}')\n",
    "print(f'F1-score: {np.round(f1_score(y_test,y_pred_test),2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Спробуємо додати Bayesian Optimization, та подивитися чи зміниться точність моделі"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_depth | min_sa... | n_esti... |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m0.738    \u001b[39m | \u001b[39m14.36    \u001b[39m | \u001b[39m9.606    \u001b[39m | \u001b[39m81.24    \u001b[39m |\n",
      "| \u001b[39m2        \u001b[39m | \u001b[39m0.7231   \u001b[39m | \u001b[39m19.97    \u001b[39m | \u001b[39m3.248    \u001b[39m | \u001b[39m40.92    \u001b[39m |\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39m0.7331   \u001b[39m | \u001b[39m6.452    \u001b[39m | \u001b[39m8.929    \u001b[39m | \u001b[39m72.08    \u001b[39m |\n",
      "| \u001b[39m4        \u001b[39m | \u001b[39m0.716    \u001b[39m | \u001b[39m22.7     \u001b[39m | \u001b[39m2.165    \u001b[39m | \u001b[39m97.89    \u001b[39m |\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39m0.7124   \u001b[39m | \u001b[39m25.81    \u001b[39m | \u001b[39m3.699    \u001b[39m | \u001b[39m42.73    \u001b[39m |\n",
      "| \u001b[39m6        \u001b[39m | \u001b[39m0.7331   \u001b[39m | \u001b[39m15.32    \u001b[39m | \u001b[39m6.897    \u001b[39m | \u001b[39m74.94    \u001b[39m |\n",
      "| \u001b[39m7        \u001b[39m | \u001b[39m0.7311   \u001b[39m | \u001b[39m5.821    \u001b[39m | \u001b[39m9.999    \u001b[39m | \u001b[39m83.35    \u001b[39m |\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39m0.7282   \u001b[39m | \u001b[39m24.54    \u001b[39m | \u001b[39m9.98     \u001b[39m | \u001b[39m80.4     \u001b[39m |\n",
      "| \u001b[35m9        \u001b[39m | \u001b[35m0.7388   \u001b[39m | \u001b[35m11.1     \u001b[39m | \u001b[35m2.024    \u001b[39m | \u001b[35m82.46    \u001b[39m |\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39m0.7311   \u001b[39m | \u001b[39m5.492    \u001b[39m | \u001b[39m2.595    \u001b[39m | \u001b[39m58.77    \u001b[39m |\n",
      "| \u001b[39m11       \u001b[39m | \u001b[39m0.7327   \u001b[39m | \u001b[39m5.037    \u001b[39m | \u001b[39m3.093    \u001b[39m | \u001b[39m35.89    \u001b[39m |\n",
      "| \u001b[39m12       \u001b[39m | \u001b[39m0.7322   \u001b[39m | \u001b[39m5.597    \u001b[39m | \u001b[39m9.602    \u001b[39m | \u001b[39m46.29    \u001b[39m |\n",
      "| \u001b[39m13       \u001b[39m | \u001b[39m0.7298   \u001b[39m | \u001b[39m5.869    \u001b[39m | \u001b[39m2.085    \u001b[39m | \u001b[39m76.7     \u001b[39m |\n",
      "| \u001b[39m14       \u001b[39m | \u001b[39m0.7269   \u001b[39m | \u001b[39m17.28    \u001b[39m | \u001b[39m2.609    \u001b[39m | \u001b[39m82.96    \u001b[39m |\n",
      "| \u001b[39m15       \u001b[39m | \u001b[39m0.7347   \u001b[39m | \u001b[39m7.697    \u001b[39m | \u001b[39m2.789    \u001b[39m | \u001b[39m87.6     \u001b[39m |\n",
      "| \u001b[39m16       \u001b[39m | \u001b[39m0.7376   \u001b[39m | \u001b[39m10.72    \u001b[39m | \u001b[39m6.128    \u001b[39m | \u001b[39m80.38    \u001b[39m |\n",
      "| \u001b[39m17       \u001b[39m | \u001b[39m0.7357   \u001b[39m | \u001b[39m16.7     \u001b[39m | \u001b[39m9.903    \u001b[39m | \u001b[39m62.2     \u001b[39m |\n",
      "| \u001b[39m18       \u001b[39m | \u001b[39m0.7241   \u001b[39m | \u001b[39m26.31    \u001b[39m | \u001b[39m9.773    \u001b[39m | \u001b[39m64.12    \u001b[39m |\n",
      "| \u001b[35m19       \u001b[39m | \u001b[35m0.7398   \u001b[39m | \u001b[35m10.14    \u001b[39m | \u001b[35m9.866    \u001b[39m | \u001b[35m63.59    \u001b[39m |\n",
      "| \u001b[39m20       \u001b[39m | \u001b[39m0.7382   \u001b[39m | \u001b[39m12.79    \u001b[39m | \u001b[39m9.99     \u001b[39m | \u001b[39m56.21    \u001b[39m |\n",
      "| \u001b[39m21       \u001b[39m | \u001b[39m0.7369   \u001b[39m | \u001b[39m12.96    \u001b[39m | \u001b[39m8.475    \u001b[39m | \u001b[39m30.15    \u001b[39m |\n",
      "| \u001b[39m22       \u001b[39m | \u001b[39m0.7309   \u001b[39m | \u001b[39m5.398    \u001b[39m | \u001b[39m9.636    \u001b[39m | \u001b[39m30.13    \u001b[39m |\n",
      "| \u001b[39m23       \u001b[39m | \u001b[39m0.7314   \u001b[39m | \u001b[39m5.541    \u001b[39m | \u001b[39m9.994    \u001b[39m | \u001b[39m58.09    \u001b[39m |\n",
      "| \u001b[39m24       \u001b[39m | \u001b[39m0.7366   \u001b[39m | \u001b[39m13.31    \u001b[39m | \u001b[39m3.365    \u001b[39m | \u001b[39m63.07    \u001b[39m |\n",
      "| \u001b[39m25       \u001b[39m | \u001b[39m0.734    \u001b[39m | \u001b[39m14.43    \u001b[39m | \u001b[39m2.398    \u001b[39m | \u001b[39m30.27    \u001b[39m |\n",
      "| \u001b[39m26       \u001b[39m | \u001b[39m0.7299   \u001b[39m | \u001b[39m5.095    \u001b[39m | \u001b[39m9.885    \u001b[39m | \u001b[39m98.91    \u001b[39m |\n",
      "| \u001b[39m27       \u001b[39m | \u001b[39m0.7359   \u001b[39m | \u001b[39m14.57    \u001b[39m | \u001b[39m2.287    \u001b[39m | \u001b[39m55.03    \u001b[39m |\n",
      "| \u001b[39m28       \u001b[39m | \u001b[39m0.7398   \u001b[39m | \u001b[39m11.83    \u001b[39m | \u001b[39m9.811    \u001b[39m | \u001b[39m37.78    \u001b[39m |\n",
      "| \u001b[39m29       \u001b[39m | \u001b[39m0.7321   \u001b[39m | \u001b[39m19.81    \u001b[39m | \u001b[39m9.971    \u001b[39m | \u001b[39m30.33    \u001b[39m |\n",
      "| \u001b[39m30       \u001b[39m | \u001b[39m0.7379   \u001b[39m | \u001b[39m12.94    \u001b[39m | \u001b[39m9.891    \u001b[39m | \u001b[39m45.22    \u001b[39m |\n",
      "=============================================================\n",
      "Best hyperparameters: {'target': 0.7397796462742824, 'params': {'max_depth': 10.143266256711401, 'min_samples_split': 9.866136195689304, 'n_estimators': 63.58600962670498}}\n"
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "def rf_evaluate(n_estimators, max_depth, min_samples_split):\n",
    "    n_estimators = int(n_estimators)\n",
    "    max_depth = int(max_depth)\n",
    "    min_samples_split = int(min_samples_split)\n",
    "    \n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "param_bounds = {\n",
    "    'n_estimators': (30, 100),\n",
    "    'max_depth': (5, 30),       \n",
    "    'min_samples_split': (2, 10) \n",
    "}\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f=rf_evaluate,\n",
    "    pbounds=param_bounds,\n",
    "    random_state=42,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "optimizer.maximize(init_points=5,n_iter=25)\n",
    "\n",
    "print(f'Best hyperparameters: {optimizer.max}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Спробуємо використати підхід до навчання моделей який має назву Blanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точність блендінгової моделі: 0.75\n",
      "Precision: 0.77\n",
      "F1-score: 0.73\n"
     ]
    }
   ],
   "source": [
    "model_rf = RandomForestClassifier(random_state=42)\n",
    "model_lr = LogisticRegression(random_state=42,max_iter=1000)\n",
    "model_knn = KNeighborsClassifier()\n",
    "\n",
    "model_rf.fit(X_train,y_train)\n",
    "model_lr.fit(X_train,y_train)\n",
    "model_knn.fit(X_train,y_train)\n",
    "\n",
    "pred_rf = model_rf.predict_proba(X_test)[:, 1]\n",
    "pred_lr = model_lr.predict_proba(X_test)[:, 1]\n",
    "pred_knn = model_knn.predict_proba(X_test)[:, 1]\n",
    "\n",
    "predictions_base = pd.DataFrame({\n",
    "    'rf': pred_rf,\n",
    "    'lr': pred_lr,\n",
    "    'knn': pred_knn\n",
    "})\n",
    "\n",
    "meta_model = GradientBoostingClassifier()\n",
    "meta_model.fit(predictions_base, y_test)\n",
    "y_pred_blend = meta_model.predict(predictions_base)\n",
    "accuracy = accuracy_score(y_test, y_pred_blend)\n",
    "print(f'Точність блендінгової моделі: {accuracy:.2f}')\n",
    "print(f'Precision: {np.round(precision_score(y_test,y_pred_test),2)}')\n",
    "print(f'F1-score: {np.round(f1_score(y_test,y_pred_test),2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визначення які ознаки є важливими"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def features_importances(X_train_f,y_train_f):\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(X_train_f, y_train_f)\n",
    "\n",
    "    feature_names = X.columns\n",
    "\n",
    "    start_time = time.time()\n",
    "    importances = rf.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in rf.estimators_], axis=0)\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    print(f\"Elapsed time to compute the importances: {elapsed_time:.3f} seconds\")\n",
    "\n",
    "    forest_importances = pd.Series(importances, index=feature_names)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "    ax.set_title(\"Feature importances using MDI\")\n",
    "    ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute the importances: 0.094 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnYAAAHWCAYAAAD6oMSKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABmmUlEQVR4nO3deVhU1f8H8PcMssmuCAihiOCCqOC+W4rgknsuuIBLZu6JmpoLrqHmllmaqall7mZ9MzHFLTdMUdxTEEURBBdAQEXg/P7wx+Q4oHMRuMP4fj3PPDHnnrnzvgzhh3PvOVchhBAgIiIiohJPKXcAIiIiIiocLOyIiIiI9AQLOyIiIiI9wcKOiIiISE+wsCMiIiLSEyzsiIiIiPQECzsiIiIiPcHCjoiIiEhPsLAjIiIi0hMs7Iio2Kxbtw4KhQI3b96UOwrJ4NChQ1AoFDh06JDcUYj0Fgs7oiKUW8jk9Zg0aVKRvOfx48cxY8YMJCcnF8n+32UZGRmYMWMGC5MS6OX/F48ePaqxXQgBZ2dnKBQKfPjhh2rbXv7/tlSpUihTpgzq1q2LMWPG4PLlyxr7unnzJhQKBRYuXFhkx0OUn1JyByB6F8yaNQuVKlVSa/P09CyS9zp+/DhmzpyJAQMGwNraukjeo6D69++P3r17w9jYWO4oBZKRkYGZM2cCAN5//315w5RALVq0wJMnT2BkZCRbBhMTE/zyyy9o1qyZWvvhw4dx586dfH8227Rpg4CAAAghkJKSgsjISKxfvx7fffcd5s+fj6CgoOKIT/RGLOyIikG7du1Qr149uWO8lfT0dJiZmb3VPgwMDGBgYFBIiYpPTk4OMjMz5Y5R4imVSpiYmMiaoX379ti2bRuWLVuGUqX++yfwl19+Qd26dXH//v08X1elShX069dPrW3evHno2LEjxo0bh2rVqqF9+/ZFmp1IGzwVS6QD9uzZg+bNm8PMzAwWFhbo0KEDLl26pNbn/PnzGDBgAFxdXWFiYgIHBwcMGjQIDx48UPWZMWMGJkyYAACoVKmS6vTRzZs3VaeH1q1bp/H+CoUCM2bMUNuPQqHA5cuX0adPH9jY2KiNcPz888+oW7cuTE1NUaZMGfTu3Ru3b99+43HmdY2di4sLPvzwQxw6dAj16tWDqakpatasqTrduXPnTtSsWRMmJiaoW7cuzp49q7bPAQMGwNzcHDdu3ICfnx/MzMzg6OiIWbNmQQih1jc9PR3jxo2Ds7MzjI2NUbVqVSxcuFCjn0KhwMiRI7Fx40bUqFEDxsbGWLlyJcqVKwcAmDlzpup7m/t90+bzefl7GxUVpRpVtbKywsCBA5GRkaHxPfv555/RoEEDlC5dGjY2NmjRogX++usvtT7a/PwkJCRg4MCBeO+992BsbIzy5cujc+fOb7ze8f33389zdHLAgAFwcXFRa9u8eTPq1q0LCwsLWFpaombNmvj6669V2/O6xu7999+Hp6cnLl++jA8++AClS5eGk5MTFixYoPGet27dQqdOnWBmZgY7OzuMHTsWe/fulXTdnr+/Px48eIB9+/ap2jIzM7F9+3b06dNHq33kKlu2LDZv3oxSpUph7ty5kl5LVFQ4YkdUDFJSUjRGAmxtbQEAP/30EwIDA+Hn54f58+cjIyMDK1asQLNmzXD27FnVP5779u3DjRs3MHDgQDg4OODSpUtYtWoVLl26hJMnT0KhUKBbt264du0aNm3ahCVLlqjeo1y5ckhKSpKcu0ePHnB3d8eXX36pKn7mzp2LadOmoWfPnvj444+RlJSEb775Bi1atMDZs2cLdPo3KioKffr0wdChQ9GvXz8sXLgQHTt2xMqVK/HFF19g+PDhAICQkBD07NkT//77L5TK//4uzc7ORtu2bdGoUSMsWLAAoaGhCA4ORlZWFmbNmgXgxTVUnTp1wsGDBzF48GB4eXlh7969mDBhAuLi4rBkyRK1TAcOHMDWrVsxcuRI2Nraonbt2lixYgWGDRuGrl27olu3bgCAWrVqAdDu83lZz549UalSJYSEhCAiIgKrV6+GnZ0d5s+fr+ozc+ZMzJgxA02aNMGsWbNgZGSE8PBwHDhwAL6+vgC0//np3r07Ll26hFGjRsHFxQWJiYnYt28fYmNjNQq0gti3bx/8/f3RunVr1TFcuXIFx44dw5gxY1772kePHqFt27bo1q0bevbsie3bt2PixImoWbMm2rVrB+BFUd6qVSvEx8djzJgxcHBwwC+//IKDBw9Kyuni4oLGjRtj06ZNqn3v2bMHKSkp6N27N5YtWyZpfxUqVEDLli1x8OBBpKamwtLSUtLriQqdIKIi8+OPPwoAeT6EEOLx48fC2tpaDBkyRO11CQkJwsrKSq09IyNDY/+bNm0SAMSRI0dUbV999ZUAIGJiYtT6xsTECADixx9/1NgPABEcHKx6HhwcLAAIf39/tX43b94UBgYGYu7cuWrtFy5cEKVKldJoz+/78XK2ihUrCgDi+PHjqra9e/cKAMLU1FTcunVL1f79998LAOLgwYOqtsDAQAFAjBo1StWWk5MjOnToIIyMjERSUpIQQohdu3YJAGLOnDlqmT766COhUChEVFSU2vdDqVSKS5cuqfVNSkrS+F7l0vbzyf3eDho0SK1v165dRdmyZVXPr1+/LpRKpejatavIzs5W65uTkyOE0P7n59GjRwKA+OqrrzQyvknLli1Fy5YtNdoDAwNFxYoVVc/HjBkjLC0tRVZWVr77OnjwoMbn17JlSwFAbNiwQdX27Nkz4eDgILp3765qW7RokQAgdu3apWp78uSJqFatmsY+85L7s/fPP/+I5cuXCwsLC9Vn1qNHD/HBBx8IIV78PHbo0EHttQDEiBEj8t33mDFjBAARGRkphPjv/7WCfL+J3hZPxRIVg2+//Rb79u1TewAvRjmSk5Ph7++P+/fvqx4GBgZo2LCh2miEqamp6uunT5/i/v37aNSoEQAgIiKiSHJ/+umnas937tyJnJwc9OzZUy2vg4MD3N3dJY+e5PLw8EDjxo1Vzxs2bAgAaNWqFSpUqKDRfuPGDY19jBw5UvV17qnUzMxM7N+/HwDw559/wsDAAKNHj1Z73bhx4yCEwJ49e9TaW7ZsCQ8PD62PQern8+r3tnnz5njw4AFSU1MBALt27UJOTg6mT5+uNjqZe3yA9j8/pqamMDIywqFDh/Do0SOtj0kKa2trpKenq53i1Ja5ubna9WtGRkZo0KCB2uccGhoKJycndOrUSdVmYmKCIUOGSH6/nj174smTJ/jjjz/w+PFj/PHHH5JPw76aHwAeP35c4H0QFRaeiiUqBg0aNMhz8sT169cBvChg8vLyaZ2HDx9i5syZ2Lx5MxITE9X6paSkFGLa/7w6k/f69esQQsDd3T3P/oaGhgV6n5eLNwCwsrICADg7O+fZ/mpxolQq4erqqtZWpUoVAFBdQ3br1i04OjrCwsJCrV/16tVV21/26rG/idTP59VjtrGxAfDi2CwtLREdHQ2lUvna4lLbnx9jY2PMnz8f48aNg729PRo1aoQPP/wQAQEBcHBw0P4gX2P48OHYunUr2rVrBycnJ/j6+qJnz55o27btG1/73nvvaZyqtrGxwfnz51XPb926hcqVK2v0c3Nzk5y1XLly8PHxwS+//IKMjAxkZ2fjo48+kryfXGlpaQCg8bNFJAcWdkQyysnJAfDiOqm8/oF9edZez549cfz4cUyYMAFeXl4wNzdHTk4O2rZtq9rP67z6D2Ku7OzsfF/z8ihUbl6FQoE9e/bkObs1d+RCqvxmyubXLl6Z7FAUXj32N5H6+RTGsUn5+fnss8/QsWNH7Nq1C3v37sW0adMQEhKCAwcOwNvbO9/3UCgUeWZ69efGzs4O586dw969e7Fnzx7s2bMHP/74IwICArB+/frXHoccn3OfPn0wZMgQJCQkoF27dm+1NNDFixdhYGAg+Y8BoqLAwo5IRpUrVwbw4h9FHx+ffPs9evQIYWFhmDlzJqZPn65qzx2xeVl+BVzuiNCrCxe/OlL1prxCCFSqVEk1IqYLcnJycOPGDbVM165dAwDVxICKFSti//79ePz4sdrIytWrV1Xb3yS/762Uz0dblStXRk5ODi5fvgwvL698+wBv/vl5uf+4ceMwbtw4XL9+HV5eXli0aBF+/vnnfF9jY2OT56nvvH5ujIyM0LFjR3Ts2BE5OTkYPnw4vv/+e0ybNq1AI2svq1ixIi5fvgwhhNrnEBUVVaD9de3aFUOHDsXJkyexZcuWAueKjY3F4cOH0bhxY47YkU7gNXZEMvLz84OlpSW+/PJLPH/+XGN77kzW3BGNV0cwli5dqvGa3LXmXi3gLC0tYWtriyNHjqi1f/fdd1rn7datGwwMDDBz5kyNLEIIjaU9itPy5cvVsixfvhyGhoZo3bo1gBfrl2VnZ6v1A4AlS5ZAoVCoZki+TunSpQFofm+lfD7a6tKlC5RKJWbNmqUx4pf7Ptr+/GRkZODp06dq2ypXrgwLCws8e/bstTkqV66Mq1evqs2qjoyMxLFjx9T6vfrZK5VK1YzhN72HNvz8/BAXF4fff/9d1fb06VP88MMPBdqfubk5VqxYgRkzZqBjx44F2sfDhw/h7++P7OxsTJkypUD7ICpsHLEjkpGlpSVWrFiB/v37o06dOujduzfKlSuH2NhY7N69G02bNsXy5cthaWmJFi1aYMGCBXj+/DmcnJzw119/ISYmRmOfdevWBQBMmTIFvXv3hqGhITp27AgzMzN8/PHHmDdvHj7++GPUq1cPR44cUY1saaNy5cqYM2cOJk+ejJs3b6JLly6wsLBATEwMfv31V3zyyScYP358oX1/tGViYoLQ0FAEBgaiYcOG2LNnD3bv3o0vvvhCtfZcx44d8cEHH2DKlCm4efMmateujb/++gu//fYbPvvsM9Xo1+uYmprCw8MDW7ZsQZUqVVCmTBl4enrC09NT689HW25ubpgyZQpmz56N5s2bo1u3bjA2NsY///wDR0dHhISEaP3zc+3aNbRu3Ro9e/aEh4cHSpUqhV9//RX37t1D7969X5tj0KBBWLx4Mfz8/DB48GAkJiZi5cqVqFGjhmqiBwB8/PHHePjwIVq1aoX33nsPt27dwjfffAMvLy/VdYxvY+jQoVi+fDn8/f0xZswYlC9fHhs3blQteJzfaOrrBAYGat332rVr+PnnnyGEQGpqKiIjI7Ft2zakpaVh8eLFWl1LSFQsZJiJS/TOeHmJhdc5ePCg8PPzE1ZWVsLExERUrlxZDBgwQJw+fVrV586dO6Jr167C2tpaWFlZiR49eoi7d+/mufzG7NmzhZOTk1AqlWrLi2RkZIjBgwcLKysrYWFhIXr27CkSExPzXe4kd6mQV+3YsUM0a9ZMmJmZCTMzM1GtWjUxYsQI8e+//2r1/Xh1uZNXl5cQIu8lJvJaRiIwMFCYmZmJ6Oho4evrK0qXLi3s7e1FcHCwxjIhjx8/FmPHjhWOjo7C0NBQuLu7i6+++kq1fMjr3jvX8ePHRd26dYWRkZHa903bzye/721e3xshhFi7dq3w9vYWxsbGwsbGRrRs2VLs27dPrc+bfn7u378vRowYIapVqybMzMyElZWVaNiwodi6dWuex/iqn3/+Wbi6ugojIyPh5eUl9u7dq7Hcyfbt24Wvr6+ws7MTRkZGokKFCmLo0KEiPj5eLSfyWO6kRo0aGu/56v6FEOLGjRuiQ4cOwtTUVJQrV06MGzdO7NixQwAQJ0+efO0xaPv/Yn7LneQ+lEqlsLa2Ft7e3mLMmDEaS+IIweVOSF4KIYrhKmQioiIyYMAAbN++XTUzkd4tS5cuxdixY3Hnzh04OTnJHYdIdrzGjoiISoQnT56oPX/69Cm+//57uLu7s6gj+n+8xo6IiEqEbt26oUKFCvDy8kJKSgp+/vlnXL16FRs3bpQ7GpHOYGFHREQlgp+fH1avXo2NGzciOzsbHh4e2Lx5M3r16iV3NCKdwWvsiIiIiPQEr7EjIiIi0hMs7IiIiIj0BK+xy0NOTg7u3r0LCwuLAi16SURERFRYhBB4/PgxHB0doVS+fkyOhV0e7t69C2dnZ7ljEBEREancvn0b77333mv7sLDLQ+6NnG/fvg1LS0uZ0xAREdG7LDU1Fc7Ozqr65HVY2OUh9/SrpaUlCzsiIiLSCdpcHsbJE0RERER6goUdERERkZ5gYUdERESkJ1jYEREREekJFnZEREREeoKFHREREZGeYGFHREREpCdY2BERERHpCRZ2RERERHqChR0RERGRnmBhR++89PR0KBQKKBQKpKenyx2HiIiowFjYEREREekJFnZEREREeoKFnQx46o+IiIiKAgs7IiIiKlYc4Cg6LOyIiIiI9AQLOyIiIiI9wcKOiIiISE+wsCMiIiLSEyzsiIiIiPQECzsiIiIiPcHCjoiIiEhPsLAjIiIi0hMs7IiIiIj0BAs7IiIiIj2hE4Xdt99+CxcXF5iYmKBhw4Y4depUvn1/+OEHNG/eHDY2NrCxsYGPj49G/wEDBqhuVZL7aNu2bVEfBhEREZGsZC/stmzZgqCgIAQHByMiIgK1a9eGn58fEhMT8+x/6NAh+Pv74+DBgzhx4gScnZ3h6+uLuLg4tX5t27ZFfHy86rFp06biOBwiIiIi2che2C1evBhDhgzBwIED4eHhgZUrV6J06dJYu3Ztnv03btyI4cOHw8vLC9WqVcPq1auRk5ODsLAwtX7GxsZwcHBQPWxsbIrjcIiIiIhkI2thl5mZiTNnzsDHx0fVplQq4ePjgxMnTmi1j4yMDDx//hxlypRRaz906BDs7OxQtWpVDBs2DA8ePCjU7ERERES6ppScb37//n1kZ2fD3t5erd3e3h5Xr17Vah8TJ06Eo6OjWnHYtm1bdOvWDZUqVUJ0dDS++OILtGvXDidOnICBgYHGPp49e4Znz56pnqemphbwiIiIiIjkI2th97bmzZuHzZs349ChQzAxMVG19+7dW/V1zZo1UatWLVSuXBmHDh1C69atNfYTEhKCmTNnFktmIiIioqIia2Fna2sLAwMD3Lt3T6393r17cHBweO1rFy5ciHnz5mH//v2oVavWa/u6urrC1tYWUVFReRZ2kydPRlBQkOp5amoqnJ2dJRzJCy6TdmvVLyfzqerr6tNCoTQyeU1vdTfndZCci4iIiN4Nsl5jZ2RkhLp166pNfMidCNG4ceN8X7dgwQLMnj0boaGhqFev3hvf586dO3jw4AHKly+f53ZjY2NYWlqqPYiIiIhKGtlPxQYFBSEwMBD16tVDgwYNsHTpUqSnp2PgwIEAgICAADg5OSEkJAQAMH/+fEyfPh2//PILXFxckJCQAAAwNzeHubk50tLSMHPmTHTv3h0ODg6Ijo7G559/Djc3N/j5+cl2nERERPqOZ67kJ3th16tXLyQlJWH69OlISEiAl5cXQkNDVRMqYmNjoVT+N7C4YsUKZGZm4qOPPlLbT3BwMGbMmAEDAwOcP38e69evR3JyMhwdHeHr64vZs2fD2Ni4WI+NiIiIqDjJXtgBwMiRIzFy5Mg8tx06dEjt+c2bN1+7L1NTU+zdu7eQkhERERGVHLIvUExEREREhYOFHREREZGeYGFHREREpCdY2BERERHpCcmFXWBgII4cOVIUWYiIiIjoLUgu7FJSUuDj4wN3d3d8+eWXiIuLK4pcRERERCSR5MJu165diIuLw7Bhw7Blyxa4uLigXbt22L59O54/f14UGYmIiIhICwW6xq5cuXIICgpCZGQkwsPD4ebmhv79+8PR0RFjx47F9evXCzsnEREREb3BW02eiI+Px759+7Bv3z4YGBigffv2uHDhAjw8PLBkyZLCykhEREREWpBc2D1//hw7duzAhx9+iIoVK2Lbtm347LPPcPfuXaxfvx779+/H1q1bMWvWrKLIS0RERET5kHxLsfLlyyMnJwf+/v44deoUvLy8NPp88MEHsLa2LoR4RERERKQtyYXdkiVL0KNHD5iYmOTbx9raGjExMW8VjIiIiIikkXwq9uDBg3nOfk1PT8egQYMKJRQRERERSSe5sFu/fj2ePHmi0f7kyRNs2LChUELpO6WRCSpO/AMVJ/4BpVH+I59EREREUmh9KjY1NRVCCAgh8PjxY7VTsdnZ2fjzzz9hZ2dXJCGJiIiI6M20Luysra2hUCigUChQpUoVje0KhQIzZ84s1HBERESkf3LPXFHh07qwO3jwIIQQaNWqFXbs2IEyZcqothkZGaFixYpwdHQskpBERERE9GZaF3YtW7YEAMTExKBChQpQKBRFFoqIiIiIpNOqsDt//jw8PT2hVCqRkpKCCxcu5Nu3Vq1ahRaOiIiIiLSnVWHn5eWFhIQE2NnZwcvLCwqFAkIIjX4KhQLZ2dmFHpKIiIiI3kyrwi4mJgblypVTfU1EREREukerwq5ixYoAXtwndubMmZg2bRoqVapUpMGIiIiISBpJCxQbGhpix44dRZWFiIiIiN6C5DtPdOnSBbt27SqCKERERET0NrRe7iSXu7s7Zs2ahWPHjqFu3bowMzNT2z569OhCC0dERERE2pNc2K1ZswbW1tY4c+YMzpw5o7ZNoVCwsCMiIiKSieTCjrNiiYiIiHST5GvsiIiIiEg3SR6xGzRo0Gu3r127tsBhiIiIiKjgJBd2jx49Unv+/PlzXLx4EcnJyWjVqlWhBSMiIiIiaSQXdr/++qtGW05ODoYNG4bKlSsXSigiIiIikq5QrrFTKpUICgrCkiVLCmN3RERERFQAhTZ5Ijo6GllZWYW1OyIiIiKSSPKp2KCgILXnQgjEx8dj9+7dCAwMLLRgRERERCSN5MLu7Nmzas+VSiXKlSuHRYsWvXHGLBEREREVHcmF3cGDB4siBxERERG9JcmFXa7ExET8+++/AICqVavCzs6u0EIRERERkXSSJ0+kpqaif//+cHR0RMuWLdGyZUs4OTmhX79+SElJKVCIb7/9Fi4uLjAxMUHDhg1x6tSpfPv+8MMPaN68OWxsbGBjYwMfHx+N/kIITJ8+HeXLl4epqSl8fHxw/fr1AmUjIiIiKikkF3ZDhgxBeHg4du/ejeTkZCQnJ+OPP/7A6dOnMXToUMkBtmzZgqCgIAQHByMiIgK1a9eGn58fEhMT8+x/6NAh+Pv74+DBgzhx4gScnZ3h6+uLuLg4VZ8FCxZg2bJlWLlyJcLDw2FmZgY/Pz88ffpUcj4iIiKikkIhhBBSXmBmZoa9e/eiWbNmau1///032rZti/T0dEkBGjZsiPr162P58uUAXix27OzsjFGjRmHSpElvfH12djZsbGywfPlyBAQEQAgBR0dHjBs3DuPHjwcApKSkwN7eHuvWrUPv3r3fuM/U1FRYWVkhJSUFlpaWWh+Ly6TdWvctqJvzOhT5e7xr0tPTYW5uDgBIS0uDmZmZzImIiEom/jtYNKTUJZJH7MqWLQsrKyuNdisrK9jY2EjaV2ZmJs6cOQMfH5//AimV8PHxwYkTJ7TaR0ZGBp4/f44yZcoAAGJiYpCQkKC2TysrKzRs2DDffT579gypqalqDyIiIqKSRnJhN3XqVAQFBSEhIUHVlpCQgAkTJmDatGmS9nX//n1kZ2fD3t5erd3e3l5t/68zceJEODo6qgq53NdJ2WdISAisrKxUD2dnZ0nHQURERKQLJM+KXbFiBaKiolChQgVUqFABABAbGwtjY2MkJSXh+++/V/WNiIgovKR5mDdvHjZv3oxDhw7BxMSkwPuZPHmy2sLLqampLO6IiIioxJFc2HXp0qXQ3tzW1hYGBga4d++eWvu9e/fg4ODw2tcuXLgQ8+bNw/79+1GrVi1Ve+7r7t27h/Lly6vt08vLK899GRsbw9jYuIBHQURERKQbJBd2wcHBhfbmRkZGqFu3LsLCwlQFY05ODsLCwjBy5Mh8X7dgwQLMnTsXe/fuRb169dS2VapUCQ4ODggLC1MVcqmpqQgPD8ewYcMKLTsRERGRrinwAsXAixmEOTk5am1SZpECL+49GxgYiHr16qFBgwZYunQp0tPTMXDgQABAQEAAnJycEBISAgCYP38+pk+fjl9++QUuLi6q6+bMzc1hbm4OhUKBzz77DHPmzIG7uzsqVaqEadOmwdHRsVBHG4mIiIh0jeTCLiYmBiNHjsShQ4fU1oUTQkChUCA7O1vS/nr16oWkpCRMnz4dCQkJ8PLyQmhoqGryQ2xsLJTK/+Z4rFixApmZmfjoo4/U9hMcHIwZM2YAAD7//HOkp6fjk08+QXJyMpo1a4bQ0NC3ug6PiIiISNdJXseuadOmEEJgzJgxsLe3h0KhUNvesmXLQg0oB65j927hOnZERIWD/w4WDSl1ieQRu8jISJw5cwZVq1YtcEAiIiIiKnyS17GrX78+bt++XRRZiIiIiOgtSB6xW716NT799FPExcXB09MThoaGattfXnqEiIiIiIqP5MIuKSkJ0dHRqlmrAKBQKAo8eYKIiIiICofkwm7QoEHw9vbGpk2b8pw8QURERETykFzY3bp1C7///jvc3NyKIg9RodF2dlZO5n/L9lSfFgqlkfbL4ryLs7OIiEh3SZ480apVK0RGRhZFFiIiIiJ6C5JH7Dp27IixY8fiwoULqFmzpsbkiU6dOhVaOCIiIiLSnuTC7tNPPwUAzJo1S2MbJ08QERERyUdyYffqvWGJiIiISDdIvsaOiIiIiHSTViN2y5YtwyeffAITExMsW7bstX1Hjx5dKMGIiIiISBqtCrslS5agb9++MDExwZIlS/Ltp1AoWNgRERERyUSrwi4mJibPr4mIiIhId/AaOyIiIiI9wcKOiIiISE+wsCMiIiLSEyzsiIiIiPQECzsiIiIiPSH5zhMAkJycjFOnTiExMVHjThQBAQGFEoyIiIiIpJFc2P3vf/9D3759kZaWBktLSygUCtU2hULBwo6IiIhIJpJPxY4bNw6DBg1CWloakpOT8ejRI9Xj4cOHRZGRiIiIiLQgubCLi4vD6NGjUbp06aLIQ0REREQFJLmw8/Pzw+nTp4siCxERERG9BcnX2HXo0AETJkzA5cuXUbNmTRgaGqpt79SpU6GFIyIiIiLtSS7shgwZAgCYNWuWxjaFQoHs7Oy3T0VEREREkkku7F5d3oSIiIiIdAMXKCYiIiLSE1qN2C1btgyffPIJTExMsGzZstf2HT16dKEEIyIiIiJptCrslixZgr59+8LExARLlizJt59CoWBhR0RERCQTrQq7mJiYPL8mIiIiIt3Ba+yIiIiI9AQLOyIiIiI9wcKOiIiISE+wsCMiIiLSEyzsiIiIiPREgQq7v//+G/369UPjxo0RFxcHAPjpp59w9OhRyfv69ttv4eLiAhMTEzRs2BCnTp3Kt++lS5fQvXt3uLi4QKFQYOnSpRp9ZsyYAYVCofaoVq2a5FxEREREJY3kwm7Hjh3w8/ODqakpzp49i2fPngEAUlJS8OWXX0ra15YtWxAUFITg4GBERESgdu3a8PPzQ2JiYp79MzIy4Orqinnz5sHBwSHf/daoUQPx8fGqR0EKTiIiIqKSRnJhN2fOHKxcuRI//PADDA0NVe1NmzZFRESEpH0tXrwYQ4YMwcCBA+Hh4YGVK1eidOnSWLt2bZ7969evj6+++gq9e/eGsbFxvvstVaoUHBwcVA9bW1tJuYhKovT0dNUodXp6utxxiIhIBpILu3///RctWrTQaLeyskJycrLW+8nMzMSZM2fg4+PzXxilEj4+Pjhx4oTUWGquX78OR0dHuLq6om/fvoiNjX1t/2fPniE1NVXtQURERFTSSC7sHBwcEBUVpdF+9OhRuLq6ar2f+/fvIzs7G/b29mrt9vb2SEhIkBpLpWHDhli3bh1CQ0OxYsUKxMTEoHnz5nj8+HG+rwkJCYGVlZXq4ezsXOD3JyIiIpKL5MJuyJAhGDNmDMLDw6FQKHD37l1s3LgR48ePx7Bhw4oioyTt2rVDjx49UKtWLfj5+eHPP/9EcnIytm7dmu9rJk+ejJSUFNXj9u3bxZiYiIiIqHBoda/Yl02aNAk5OTlo3bo1MjIy0KJFCxgbG2P8+PEYNWqU1vuxtbWFgYEB7t27p9Z+7969106MkMra2hpVqlTJc5Qxl7Gx8Wuv2SMiIiIqCSSP2CkUCkyZMgUPHz7ExYsXcfLkSSQlJWH27NmS9mNkZIS6desiLCxM1ZaTk4OwsDA0btxYaqx8paWlITo6GuXLly+0fRIRERHpIskjdrmMjIzg4eGB1NRU7N+/H1WrVkX16tUl7SMoKAiBgYGoV68eGjRogKVLlyI9PR0DBw4EAAQEBMDJyQkhISEAXky4uHz5surruLg4nDt3Dubm5nBzcwMAjB8/Hh07dkTFihVx9+5dBAcHw8DAAP7+/gU9VCIiIqISQXJh17NnT7Ro0QIjR47EkydPUL9+fcTExEAIgc2bN6N79+5a76tXr15ISkrC9OnTkZCQAC8vL4SGhqomVMTGxkKp/G9Q8e7du/D29lY9X7hwIRYuXIiWLVvi0KFDAIA7d+7A398fDx48QLly5dCsWTOcPHkS5cqVk3qoRERERCWK5MLuyJEjmDJlCgDg119/RU5ODpKTk7F+/XrMmTNHUmEHACNHjsTIkSPz3JZbrOVycXGBEOK1+9u8ebOk9yciIiLSF5KvsUtJSUGZMmUAAKGhoejevTtKly6NDh064Pr164UekIiIiIi0I7mwc3Z2xokTJ5Ceno7Q0FD4+voCAB49egQTE5NCD0hERERE2pF8Kvazzz5D3759YW5ujooVK+L9998H8OIUbc2aNQs7HxERERFpSXJhN3z4cDRs2BCxsbFo06aNanKDq6sr5syZU+gBiYiIiEg7BVrupG7duqhbt65aW4cOHQolEBEREREVTIEKuzt37uD3339HbGwsMjMz1bYtXry4UIIRERERkTSSC7uwsDB06tQJrq6uuHr1Kjw9PXHz5k0IIVCnTp2iyEhEREREWpA8K3by5MkYP348Lly4ABMTE+zYsQO3b99Gy5Yt0aNHj6LISERERERakFzYXblyBQEBAQCAUqVK4cmTJzA3N8esWbMwf/78Qg9IRERERNqRXNiZmZmprqsrX748oqOjVdvu379feMmIiIiISBLJ19g1atQIR48eRfXq1dG+fXuMGzcOFy5cwM6dO9GoUaOiyEhEREREWpBc2C1evBhpaWkAgJkzZyItLQ1btmyBu7s7Z8QSERERyUhyYefq6qr62szMDCtXrizUQERERERUMJKvsQOA5ORkrF69GpMnT8bDhw8BABEREYiLiyvUcERERESkPckjdufPn4ePjw+srKxw8+ZNDBkyBGXKlMHOnTsRGxuLDRs2FEVOIiIiInoDySN2QUFBGDBgAK5fvw4TExNVe/v27XHkyJFCDUdERERE2pNc2P3zzz8YOnSoRruTkxMSEhIKJRQRERERSSe5sDM2NkZqaqpG+7Vr11CuXLlCCUVERERE0kku7Dp16oRZs2bh+fPnAACFQoHY2FhMnDgR3bt3L/SARERERKQdyYXdokWLkJaWBjs7Ozx58gQtW7aEm5sbLCwsMHfu3KLISERERERakDwr1srKCvv27cOxY8cQGRmJtLQ01KlTBz4+PkWRj4iIiIi0JKmwe/78OUxNTXHu3Dk0bdoUTZs2LapcRERERCSRpFOxhoaGqFChArKzs4sqDxEREREVkORr7KZMmYIvvvhCdccJIiIiItINkq+xW758OaKiouDo6IiKFSvCzMxMbXtEREShhSMiIiIi7Uku7Lp06VIEMYiIiIjobUku7IKDg4siBxERERG9pQLdUiw8PFyjPTw8HKdPny6UUEREREQkneTCbsSIEbh9+7ZGe1xcHEaMGFEooYiIiIhIOsmF3eXLl1GnTh2Ndm9vb1y+fLlQQhERERGRdJILO2NjY9y7d0+jPT4+HqVKSb5kj4iIiIgKieTCztfXF5MnT0ZKSoqqLTk5GV988QXatGlTqOGIiIiISHuSh9gWLlyIFi1aoGLFivD29gYAnDt3Dvb29vjpp58KPSARERERaUdyYefk5ITz589j48aNiIyMhKmpKQYOHAh/f38YGhoWRUYiIiIi0kKBLoozMzPDJ598UthZiIiIiOgtSL7GDgB++uknNGvWDI6Ojrh16xYAYMmSJfjtt98KNRwRERERaU9yYbdixQoEBQWhXbt2ePToEbKzswEANjY2WLp0qeQA3377LVxcXGBiYoKGDRvi1KlT+fa9dOkSunfvDhcXFygUinzfT8o+iYiIiPSF5MLum2++wQ8//IApU6aoLW9Sr149XLhwQdK+tmzZgqCgIAQHByMiIgK1a9eGn58fEhMT8+yfkZEBV1dXzJs3Dw4ODoWyTyKlkQkqTvwDFSf+AaWRidxxiIiICkxyYRcTE6OaDfsyY2NjpKenS9rX4sWLMWTIEAwcOBAeHh5YuXIlSpcujbVr1+bZv379+vjqq6/Qu3dvGBsbF8o+iYiIiPSF5MKuUqVKOHfunEZ7aGgoqlevrvV+MjMzcebMGfj4+PwXRqmEj48PTpw4ITVWke2TiIiIqKSQPCs2KCgII0aMwNOnTyGEwKlTp7Bp0yaEhIRg9erVWu/n/v37yM7Ohr29vVq7vb09rl69KjXWW+3z2bNnePbsmep5ampqgd6fiIiISE6SC7uPP/4YpqammDp1KjIyMtCnTx84Ojri66+/Ru/evYsiY5ELCQnBzJkz5Y5BRERE9FYKtNxJ3759cf36daSlpSEhIQF37tzB4MGDJe3D1tYWBgYGGvedvXfvXr4TI4pqn7m3SMt93L59u0DvT0RERCSnAhV2uUqXLg07O7sCvdbIyAh169ZFWFiYqi0nJwdhYWFo3Lhxse7T2NgYlpaWag8iIiKikkarU7He3t5QKBRa7TAiIkLrNw8KCkJgYCDq1auHBg0aYOnSpUhPT8fAgQMBAAEBAXByckJISAiAF5MjLl++rPo6Li4O586dg7m5Odzc3LTaJxEREZG+0qqw69Kli+rrp0+f4rvvvoOHh4dqFOzkyZO4dOkShg8fLunNe/XqhaSkJEyfPh0JCQnw8vJCaGioavJDbGwslMr/BhXv3r2rttTKwoULsXDhQrRs2RKHDh3Sap9ERERE+kohhBBSXvDxxx+jfPnymD17tlp7cHAwbt++rRfrxaWmpsLKygopKSmSTsu6TNpdhKleuDmvQ5G/h7541z6P9PR0mJubAwDS0tJgZmYmcyIiete8a793i4uUukTyNXbbtm1DQECARnu/fv2wY8cOqbsjIiIiokIiubAzNTXFsWPHNNqPHTsGExPejomIiIhILpLXsfvss88wbNgwREREoEGDBgCA8PBwrF27FtOmTSv0gERERESkHcmF3aRJk+Dq6oqvv/4aP//8MwCgevXq+PHHH9GzZ89CD0j0rtP2mpWczKeqr6tPC4XSSPsR9HfxmhUioreli9c2Sy7sAKBnz54s4oiIiIh0zFstUExEREREuoOFHREREZGeYGFHREREpCdY2BERERHpCRZ2RERERHpC8qzY7OxsrFu3DmFhYUhMTEROTo7a9gMHDhRaOCIiIiLSnuTCbsyYMVi3bh06dOgAT09PKBSKoshFRERERBJJLuw2b96MrVu3on379kWRh4iIiIgKSPI1dkZGRnBzcyuKLERERET0FiQXduPGjcPXX38NIURR5CEiIiKiApJ8Kvbo0aM4ePAg9uzZgxo1asDQ0FBt+86dOwstHBERERFpT3JhZ21tja5duxZFFiIiIiJ6C5ILux9//LEochARERHRW+ICxURERER6QvKIHQBs374dW7duRWxsLDIzM9W2RUREFEowIiIiIpJG8ojdsmXLMHDgQNjb2+Ps2bNo0KABypYtixs3bqBdu3ZFkZGIiIiItCC5sPvuu++watUqfPPNNzAyMsLnn3+Offv2YfTo0UhJSSmKjERERESkBcmFXWxsLJo0aQIAMDU1xePHjwEA/fv3x6ZNmwo3HRERERFpTXJh5+DggIcPHwIAKlSogJMnTwIAYmJiuGgxERERkYwkF3atWrXC77//DgAYOHAgxo4dizZt2qBXr15c346IiIhIRpJnxa5atQo5OTkAgBEjRqBs2bI4fvw4OnXqhKFDhxZ6QCIiIqLi5DJpt1b9cjKfqr6uPi0USiMTrd/j5rwOknNpQ3Jhp1QqoVT+N9DXu3dv9O7du1BDEREREZF0BVqg+O+//0a/fv3QuHFjxMXFAQB++uknHD16tFDDEREREZH2JBd2O3bsgJ+fH0xNTXH27Fk8e/YMAJCSkoIvv/yy0AMSERERkXYkF3Zz5szBypUr8cMPP8DQ0FDV3rRpU951goiIiEhGkgu7f//9Fy1atNBot7KyQnJycmFkIiIiIqICKNA6dlFRURrtR48ehaura6GEIqJ3V3p6OhQKBRQKBdLT0+WOQ0RUokgu7IYMGYIxY8YgPDwcCoUCd+/excaNGzF+/HgMGzasKDISERERkRYkL3cyadIk5OTkoHXr1sjIyECLFi1gbGyM8ePHY9SoUUWRkYiIiIi0ILmwUygUmDJlCiZMmICoqCikpaXBw8MD5ubmRZGPiIiIiLQkubDLZWRkBA8Pj8LMQkRERERvQevCbtCgQVr1W7t2reQQ3377Lb766iskJCSgdu3a+Oabb9CgQYN8+2/btg3Tpk3DzZs34e7ujvnz56N9+/aq7QMGDMD69evVXuPn54fQ0FDJ2YiIiIhKCq0nT6xbtw4HDx5EcnIyHj16lO9Dqi1btiAoKAjBwcGIiIhA7dq14efnh8TExDz7Hz9+HP7+/hg8eDDOnj2LLl26oEuXLrh48aJav7Zt2yI+Pl712LRpk+RsRERERCWJ1iN2w4YNw6ZNmxATE4OBAweiX79+KFOmzFsHWLx4MYYMGYKBAwcCAFauXIndu3dj7dq1mDRpkkb/r7/+Gm3btsWECRMAALNnz8a+ffuwfPlyrFy5UtXP2NgYDg4Ob52PiIiIqKTQurD79ttvsXjxYuzcuRNr167F5MmT0aFDBwwePBi+vr5QKBSS3zwzMxNnzpzB5MmTVW1KpRI+Pj44ceJEnq85ceIEgoKC1Nr8/Pywa9cutbZDhw7Bzs4ONjY2aNWqFebMmYOyZctKzkhEhcNl0m6t+uVkPlV9XX1aKJRGJlq/x815HSTnIiLSJ5LWsTM2Noa/vz/27duHy5cvo0aNGhg+fDhcXFyQlpYm+c3v37+P7Oxs2Nvbq7Xb29sjISEhz9ckJCS8sX/btm2xYcMGhIWFYf78+Th8+DDatWuH7OzsPPf57NkzpKamqj2IiIiISpoCz4pVKpVQKBQQQuRbMMmld+/eqq9r1qyJWrVqoXLlyjh06BBat26t0T8kJAQzZ84szohEREREhU7SiN2zZ8+wadMmtGnTBlWqVMGFCxewfPlyxMbGFmgdO1tbWxgYGODevXtq7ffu3cv3+jgHBwdJ/QHA1dUVtra2ed4KDQAmT56MlJQU1eP27dsSj4SIiIhIfloXdsOHD0f58uUxb948fPjhh7h9+za2bduG9u3bQ6mUfGcyAC/Wwqtbty7CwsJUbTk5OQgLC0Pjxo3zfE3jxo3V+gPAvn378u0PAHfu3MGDBw9Qvnz5PLcbGxvD0tJS7UFERERU0mh9KnblypWoUKECXF1dcfjwYRw+fDjPfjt37pQUICgoCIGBgahXrx4aNGiApUuXIj09XTVLNiAgAE5OTggJCQEAjBkzBi1btsSiRYvQoUMHbN68GadPn8aqVasAAGlpaZg5cya6d+8OBwcHREdH4/PPP4ebmxv8/PwkZSMiIiIqSbQu7AICAgo08/VNevXqhaSkJEyfPh0JCQnw8vJCaGioaoJEbGys2ohgkyZN8Msvv2Dq1Kn44osv4O7ujl27dsHT0xMAYGBggPPnz2P9+vVITk6Go6MjfH19MXv2bBgbGxd6fiIiIiJdoXVht27duiILMXLkSIwcOTLPbYcOHdJo69GjB3r06JFnf1NTU+zdu7cw4xERERGVCAWeFUtEVBSURiaoOPEPuWMQEZVILOyIiIiICkAX/xAt2HRWIiIiItI5LOyIiIiI9AQLOyIiIiI9wcKOiIiISE+wsCMiIiLSEyzsiIiIiPQECzsiIiIiPcHCjoioCKSnp0OhUEChUCA9PV3uOET0jmBhRwXGf7iIiIh0Cws7IiIiIj3Bwo6IiIhIT7CwIyIiItITpeQOQLrHZdJurfrlZD5VfV19WiiURiZav8fNeR0k56LX08WbUesj/v9BckpPT4e5uTkAIC0tDWZmZjInIl3DETsiIiIiPcHCjoiIiEhPsLAjIiIi0hO8xo4KjNd0EREVDl67SYWFhR0RURHgHz5EJAeeiiUiIiLSEyzsiIiIiPQECzsiIiIiPcFr7IiIiEoIXrtJb8IROyIiIiI9wcKOiIjylZ6eDoVCAYVCgfT0dLnjENEbsLAjIiIi0hO8xo6I6B3EBXGJ9BNH7IiISO/xlDK9K1jYEREREekJnoolIqJ86fryGjylTKSOhR0REek9XS9QiQoLT8USERER6QkWdkRERER6goUdERERkZ5gYUdERESkJ1jYEREREekJnSjsvv32W7i4uMDExAQNGzbEqVOnXtt/27ZtqFatGkxMTFCzZk38+eefatuFEJg+fTrKly8PU1NT+Pj44Pr160V5CERERESyk72w27JlC4KCghAcHIyIiAjUrl0bfn5+SExMzLP/8ePH4e/vj8GDB+Ps2bPo0qULunTpgosXL6r6LFiwAMuWLcPKlSsRHh4OMzMz+Pn54enTp3nuk4iIiEgfyF7YLV68GEOGDMHAgQPh4eGBlStXonTp0li7dm2e/b/++mu0bdsWEyZMQPXq1TF79mzUqVMHy5cvB/BitG7p0qWYOnUqOnfujFq1amHDhg24e/cudu3aVYxHRkRERFS8ZF2gODMzE2fOnMHkyZNVbUqlEj4+Pjhx4kSerzlx4gSCgoLU2vz8/FRFW0xMDBISEuDj46PabmVlhYYNG+LEiRPo3bu3xj6fPXuGZ8+eqZ6npKQAAFJTUyUdT86zDEn9C0JqpoLgcWiPx6E9Hof2eBza43Foj8ehPV07jty+Qog39pW1sLt//z6ys7Nhb2+v1m5vb4+rV6/m+ZqEhIQ8+yckJKi257bl1+dVISEhmDlzpka7s7OzdgdSjKyWyp2gcPA4dAuPQ7fwOHQLj0O3vMvH8fjxY1hZWb22D28pBmDy5Mlqo4A5OTl4+PAhypYtC4VCUSTvmZqaCmdnZ9y+fRuWlpZF8h7FgcehW3gcuoXHoVt4HLqFx6E9IQQeP34MR0fHN/aVtbCztbWFgYEB7t27p9Z+7949ODg45PkaBweH1/bP/e+9e/dQvnx5tT5eXl557tPY2BjGxsZqbdbW1lIOpcAsLS1L9A90Lh6HbuFx6BYeh27hcegWHod23jRSl0vWyRNGRkaoW7cuwsLCVG05OTkICwtD48aN83xN48aN1foDwL59+1T9K1WqBAcHB7U+qampCA8Pz3efRERERPpA9lOxQUFBCAwMRL169dCgQQMsXboU6enpGDhwIAAgICAATk5OCAkJAQCMGTMGLVu2xKJFi9ChQwds3rwZp0+fxqpVqwAACoUCn332GebMmQN3d3dUqlQJ06ZNg6OjI7p06SLXYRIREREVOdkLu169eiEpKQnTp09HQkICvLy8EBoaqpr8EBsbC6Xyv4HFJk2a4JdffsHUqVPxxRdfwN3dHbt27YKnp6eqz+eff4709HR88sknSE5ORrNmzRAaGgoTE5NiP778GBsbIzg4WOMUcEnD49AtPA7dwuPQLTwO3cLjKBoKoc3cWSIiIiLSebIvUExEREREhYOFHREREZGeYGFHREREpCdY2BERERHpCRZ2JEl2djaOHDmC5ORkuaMQERHRK1jYySAqKgp79+7FkydPAGh3U19dYWBgAF9fXzx69EjuKJQHIUSJ+nnSRzExMbh+/bpG+/Xr13Hz5s3iD/QWkpOTsXr1akyePBkPHz4EAERERCAuLk7mZO+m6OhoTJ06Ff7+/khMTAQA7NmzB5cuXZI5GekSFnbF6MGDB/Dx8UGVKlXQvn17xMfHAwAGDx6McePGyZxOe56enrhx44bcMQqkTp06qqLU29sbderUyfdRkmzYsAE1a9aEqakpTE1NUatWLfz0009yx3ojGxsblClTRqtHSTFgwAAcP35coz08PBwDBgwo/kAFdP78eVSpUgXz58/HwoULVaP0O3fuxOTJk+UNJ1F0dDRGjRoFHx8f+Pj4YPTo0YiOjpY7liSHDx9GzZo1ER4ejp07dyItLQ0AEBkZieDgYJnTvXuSkpLy3XbhwoViTKJJ9gWK3yVjx45FqVKlEBsbi+rVq6vae/XqhaCgICxatEjGdNqbM2cOxo8fj9mzZ6Nu3bowMzNT267L9/zr3LmzahFJfbkTyeLFizFt2jSMHDkSTZs2BQAcPXoUn376Ke7fv4+xY8fKnDB/S5culTtCoTt79qzqc3hZo0aNMHLkSBkSFUxQUBAGDBiABQsWwMLCQtXevn179OnTR8Zk0uzduxedOnWCl5eX6nM5duwYatSogf/9739o06aNzAm1M2nSJMyZMwdBQUFqn0erVq2wfPlyGZO9WZkyZXDt2jXY2trCxsYGCoUi3765I8O6rmbNmlizZg06dOig1r5w4UJMmzZNdUZOFoKKjb29vTh37pwQQghzc3MRHR0thBAiOjpamJmZyRlNEoVCoXoolUrVI/c5FS8XFxexfv16jfZ169YJFxcXGRK92ywtLUVERIRG++nTp4W5ubkMiQrG0tJSREVFCSHUf1/dvHlTGBsbyxlNEi8vLzFx4kSN9okTJwpvb28ZEhWMmZmZuHHjhhBC/fOIiYnR+c9j3bp14unTp6qvX/coKebPny+MjY3Fp59+KjIyMsSdO3dEq1atRLly5cTOnTtlzcYRu2KUnp6O0qVLa7Q/fPhQZ25Foo2DBw/KHaFQZWZmIjExETk5OWrtFSpUkCmRNPHx8WjSpIlGe5MmTVSn+0uK7Oxs7Nq1C1euXAEA1KhRA506dYKBgYHMybTXokULhISEYNOmTarc2dnZCAkJQbNmzWROpz1jY2OkpqZqtF+7dg3lypWTIVHBXLlyBVu3btVoHzRoUIkaMba2tkZ8fDwqVaqk1n727Fk4OTnJlEo7gYGBeX5dkn3++edo06YN+vfvj1q1auHhw4do2LAhzp8/DwcHB1mzsbArRs2bN8eGDRswe/ZsAIBCoUBOTg4WLFiADz74QOZ02mvZsqXcEQrFtWvXMHjwYI3roYQQUCgUyM7OlimZNG5ubti6dSu++OILtfYtW7bA3d1dplTSRUVFoX379oiLi0PVqlUBACEhIXB2dsbu3btRuXJlmRNqZ/78+WjRogWqVq2K5s2bAwD+/vtvpKam4sCBAzKn016nTp0wa9YsVVGkUCgQGxuLiRMnonv37jKn0165cuVw7tw5jf8Xzp07Bzs7O5lSSde7d29MnDgR27ZtU/3bcezYMYwfPx4BAQFyx5MsMTExzz+oa9WqJVMi6dzc3ODp6YkdO3YAeHFZldxFHQCeii1OFy5cEHZ2dqJt27bCyMhIfPTRR6J69erC3t5edcqjpDhy5Ijo27evaNy4sbhz544QQogNGzaIv//+W+Zk2mvSpIlo0aKF+PPPP8XZs2fFuXPn1B4lxfbt24WBgYHw8/MTs2bNErNmzRJ+fn6iVKlSsp8SkKJdu3aibdu24sGDB6q2+/fvi7Zt24r27dvLmEy6uLg4MXnyZNG+fXvRvXt3MXPmTLXjKgmSk5OFj4+PsLa2FgYGBsLZ2VkYGhqKFi1aiLS0NLnjaW3mzJnC2tpazJs3Txw5ckQcOXJEhISECGtrazFr1iy542nt2bNn4uOPPxalSpUSCoVCGBoaCqVSKfr16yeysrLkjqe106dPixo1aqgu33n10p6S4ujRo8LFxUXUqVNHXL58Wfzwww/CwsJC9OzZUzx8+FDWbAohuDZCcUpJScHy5csRGRmJtLQ01KlTByNGjED58uXljqa1HTt2oH///ujbty9++uknXL58Ga6urli+fDn+/PNP/Pnnn3JH1IqZmRnOnDmDatWqyR3lrZ05cwZLlixRncKsXr06xo0bB29vb5mTac/MzAwnT55EzZo11dojIyPRtGlT1SxAKl7Hjh1T+33l4+OjGtUuCYQQWLp0KRYtWoS7d+8CABwdHTFhwgSMHj26xBxHrtjYWFy8eBFpaWnw9vYuUaPyAFC7dm1UrlwZEydOhL29vcb3v2LFijIlk8bY2Bhjx47F7NmzYWhoCODF7Ot+/frh9u3buHPnjmzZWNiRZN7e3hg7diwCAgJgYWGByMhIuLq64uzZs2jXrh0SEhLkjqiV+vXrY8mSJSXquid9VqZMGfzxxx8a1wseO3YMHTt2LDGz5Y4cOfLa7S1atCimJG/nq6++woQJEzTas7Oz0a9fP2zatEmGVG/n8ePHAKA2q7SkOHr0qF78rrKwsMDZs2fh5uYmd5S3cvjw4TwvS8rJycHcuXMxbdo0GVK9wMKuGJ0/fz7PdoVCARMTE1SoUKFETKIoXbo0Ll++DBcXF7XC7saNG/Dw8MDTp0/ljpivly8GP336NKZOnYovv/wSNWvWVP3VlUuXl23J66L2/OjycbwsICAAERERWLNmDRo0aADgxdpvQ4YMQd26dbFu3Tp5A2pJqdRcHvTlUYmScu2mnZ0dQkJCMHjwYFVbdnY2evfujYsXL6pGh3VdTEwMsrKyNEa2rl+/DkNDQ7i4uMgTTCIjIyM4OTnB398f/fr1g4eHh9yRCqRLly7o379/ibpO83WioqIQHR2NFi1awNTUVCdGszl5ohh5eXmpPvDcevrlHwBDQ0P06tUL33//PUxMTGTJqA0HBwdERUVp/EI8evQoXF1d5QmlJWtra7XvuRACrVu3VusjSsDkiVePIy8l4ThetmzZMgQGBqJx48aqIjsrKwudOnXC119/LXM67b16V5bnz5/j7NmzmDZtGubOnStTKul2794NX19fWFlZ4aOPPkJWVhZ69uyJq1evlqiZ8QMGDMCgQYM0Crvw8HCsXr0ahw4dkieYRHfv3sXmzZuxadMmzJs3D7Vq1ULfvn3h7++P9957T+54Wlu9ejUCAwNx8eJFeHp6avxB3alTJ5mSSfPgwQP07NkTBw8ehEKhwPXr1+Hq6orBgwejTJkyWLhwoWzZOGJXjH777TdMnDgREyZMUI1InDp1CosWLUJwcDCysrIwadIk9OrVS9YfijcJCQnBzz//jLVr16JNmzb4888/cevWLYwdOxbTpk3DqFGj5I6Yr8OHD2vdV5dn/+rLceQSQuD27dsoV64c4uLi1K4VLOmnbHIdPnwYQUFBOHPmjNxRtHbgwAF06dIFP//8M9asWYOoqCgcOHAA9vb2ckfTmqWlJSIiIjR+jqKiolCvXr0Sed/rmJgY/PLLL9i0aROuXr2KFi1alJgZ1//73//Qv3//PM86lKQ/RAMCApCYmIjVq1ejevXqqjNXe/fuRVBQkLy3eSv++Rrvrvr164vQ0FCN9tDQUFG/fn0hhBC//vqrcHV1Le5okuTk5Ig5c+YIMzMz1WwmExMTMXXqVLmjFYlhw4aJpKQkuWO8NV0+juzsbGFoaCiuXbsmd5Qic+XKlRK1EHmuX3/9VZQqVUrUrFlTZ39+XkdfFox+VVZWlvjf//4nvLy8StRs0ooVK4oRI0aIhIQEuaO8FV2+4QBH7IqRqakpzp49qzEL8+rVq/D29saTJ09w8+ZNeHh4ICMjQ6aU2svMzERUVBTS0tLg4eEBc3NzuSMVCUtLS5w7d07nTzO/ia4fR40aNbBmzRo0atRI7ihv5dVraYUQiI+Px7x585CVlYWjR4/KlOzNunXrlmf7yZMn4ebmBltbW1Xbzp07iyvWW+nYsSNMTU01Fozu1asX0tPTsWfPHpkTSnPs2DFs3LgR27dvx9OnT9G5c2f07dsXbdu2lTuaViwsLHDu3LkSsy5lfiwsLBAREQF3d3e1a81Pnz4NPz8/PHjwQLZsvMauGFWrVg3z5s3DqlWrYGRkBODF9Tfz5s1TFXtxcXEl5jSHkZFRib2AVwp9+dtH149j3rx5mDBhAlasWAFPT0+54xRY7rW0r36/GzVqhLVr18qUSjtWVlZ5tvv5+RVzksKjLwtGT548GZs3b8bdu3fRpk0bfP311+jcuXOedzPSZd26dcPBgwdLfGGnyzcc4IhdMTp+/Dg6deoEpVKpWl37woULyM7Oxh9//IFGjRrhp59+QkJCQp7LDMgpv7/k81JS/pLX1st/jZVkun4cNjY2yMjIQFZWFoyMjGBqaqq2vaQsd3Lr1i2150qlEuXKldPpCVH67u7du6r1Q01NTVGrVi2MHDkSZcqUkTua1po2bYq+ffuiZ8+eaiOnJc3cuXOxdOlSdOjQIc/VCEaPHi1TMmkuXryI1q1bo06dOjhw4AA6deqES5cu4eHDhzh27JishSsLu2L2+PFjbNy4EdeuXQMAVK1aFX369NH5dZUGDhyo+loIgV9//RVWVlaoV68egBcL5CYnJ6Nbt2748ccf5YpZJHS9INKWrh/H+vXrX7tdX+4xWdIkJSXh33//BfDi91VJuk8s6Z5X73X7MoVCgRs3bhRjmrejqzccYGEng8uXLyM2NhaZmZlq7SVlmvfEiRPx8OFDrFy5Uu2aleHDh8PS0hJfffWVzAkLl64XRNrSl+PQRcuWLdO6b0kZkUhPT8eoUaOwYcMG1f08DQwMEBAQgG+++UanTwHmt2ZoXnT53qS///472rVrB0NDQ/z++++v7VtS/v14mchj2S96eyzsitGNGzfQtWtXXLhwQXUNTklcuLRcuXI4evSo6kbtuf799180adJE1otGi4K+FEQl4Tiio6Px448/Ijo6Gl9//TXs7OywZ88eVKhQATVq1JA7Xr5eNwrxspI0IjF06FDs378fy5cvR9OmTQG8WKty9OjRaNOmDVasWCFzwvwplco8r3N8la4vr6FUKpGQkAA7O7s8F77OpevH8ao1a9ZgyZIluH79OgDA3d0dn332GT7++GOZk71eSfmDgZMnitGYMWNQqVIlhIWFoVKlSggPD8fDhw8xbtw4nV637lVZWVm4evWqRmF39epV1V/2+qRfv34l5u4Nr6Prx3H48GG0a9cOTZs2xZEjRzB37lzY2dkhMjISa9aswfbt2+WOmK+YmBi5IxS6HTt2YPv27Xj//fdVbe3bt4epqSl69uyp04WdvnweL/8+1ZffrdOnT8fixYsxatQoNG7cGABw4sQJjB07FrGxsZg1a5bMCfP38sSoVxe6B3TnDjMcsStGtra2OHDgAGrVqgUrKyucOnUKVatWxYEDBzBu3DicPXtW7ohaCQoKwoYNG/DFF1+o3fpp3rx56N+/PxYvXixzQu09evQIa9asUVsQd9CgQSXqompAP46jcePG6NGjB4KCgtRGF0+dOoVu3brJelNtKYKCgvJsz711oJubGzp37qzzn03p0qVx5swZVK9eXa390qVLaNCgAdLT02VKVjB5XQKjUCjQsWNHGVNpb8OGDejVq5fGbSczMzOxefNmBAQEyJRMmnLlymHZsmXw9/dXa9+0aRNGjRqF+/fvy5TszV6eGHX27FmMHz8eEyZMUCtQFy1ahAULFqBLly4ypQQXKC5O1tbW4saNG0IIIVxdXcWBAweEEEJERUUJU1NTOaNJkp2dLebPny8cHR1VCxQ7OjqK+fPni6ysLLnjae3w4cPCyspKODs7i65du4quXbuKChUqCEtLS3H48GG542lNX47DzMxM9f/Hywt+xsTECGNjYzmjSfL+++8LS0tLYWZmJurUqSPq1KkjzM3NhZWVlWjYsKGwtrYWNjY24tKlS3JHfa1WrVqJHj16iCdPnqjaMjIyRI8ePUTr1q1lTCZNdHS0qFWrllAoFEKpVKp+ZymVyhK1sK9SqRT37t3TaL9//36JOg4rK6s8FyL/999/hZWVVfEHKqD69euL3bt3a7Tv3r1b1KlTR4ZE/2FhV4yaNWsmfv31VyGEEP7+/qJt27bi6NGjIiAgQNSoUUPecAWUkpIiUlJS5I5RIJ6enmLIkCFqxWhWVpb45JNPhKenp4zJpNGX43BychLHjh0TQqgXdjt37tT5u7G8bMmSJaJbt25q/18kJyeLjz76SCxdulSkp6eLzp07C19fXxlTvtmFCxeEo6OjKFu2rGjVqpVo1aqVKFu2rHBychIXL16UO57WPvzwQ9G5c2eRlJQkzM3NxaVLl8Tff/8tGjRoII4cOSJ3PK0pFAqRmJio0X7u3DlhY2MjQ6KCGTlypBg7dqxG+7hx48Tw4cNlSFQwJiYm4vLlyxrtly9fFiYmJjIk+g9PxRajvXv3Ij09Hd26dUNUVBQ+/PBDXLt2DWXLlsWWLVvQqlUruSO+U0xNTXHu3Lk8J4F4eXnhyZMnMiWTRl+OY/z48QgPD8e2bdtQpUoVRERE4N69ewgICEBAQACCg4PljqgVJycn7Nu3T2Px7kuXLsHX1xdxcXGIiIiAr6+vTp92AoCMjAxs3LgRV69eBfDiFH/fvn011hjUZSX9Ehhvb28oFApERkaiRo0aKFXqv0vjs7OzERMTg7Zt22Lr1q0ypny9ly9PyMrKwrp161ChQgXVXWbCw8MRGxurmnFdEtSpUweenp5YvXq16oYDmZmZ+Pjjj3Hx4kVERETIlo2TJ4rRy6u3u7m54erVq3j48CFsbGxK1HTve/fuYfz48QgLC0NiYqLGzLOSMjurTp06uHLlikZBdOXKFdSuXVumVNLpy3F8+eWXGDFiBJydnZGdnQ0PDw9kZ2ejT58+mDp1qtzxtJaSkoLExESNwi4pKUl143Nra2uN5Y50UenSpTFkyBC5Y7yV7Oxs1Tqhtra2uHv3LqpWrYqKFSuq1ufTZbnXap07dw5+fn5qt240MjKCi4sLunfvLlM67bxaPNetWxfAi1nwwIvPxdbWFpcuXSr2bAW1cuVKdOzYEe+9955qBuz58+ehUCjwv//9T9ZsLOxkpusXUOdlwIABiI2NxbRp01C+fPkSVZS+bPTo0RgzZgyioqJUfzmePHkS3377LebNm6c2tV2X17rSl+MwMjLCDz/8gOnTp+PChQtIS0uDt7c33N3d5Y4mSefOnTFo0CAsWrQI9evXBwD8888/GD9+vOof6VOnTqFKlSoyptTO3bt3cfToUSQmJmrMyiwp6/F5enoiMjISlSpVQsOGDbFgwQIYGRlh1apVOr30T67ckWoXFxf07t1bY/JESXDw4EG5IxS6Bg0a4MaNG2oj2r169UKfPn1gZmYmazaeiiXJLCws8Pfff8PLy0vuKG/ldetCAVCb1q7Lo5D6chyzZs3C+PHjNRa+ffLkCb766itMnz5dpmTSpKWlYezYsdiwYQOysrIAAKVKlUJgYCCWLFkCMzMznDt3DgB0+v+hdevWYejQoTAyMkLZsmXV/oArSevx6cslMP/88w9ycnLQsGFDtfbw8HAYGBio7gJExMKOJPPw8MDGjRvh7e0td5S38uo9PV+nYsWKRZjk7ejLcRgYGCA+Ph52dnZq7Q8ePICdnZ1OF6V5SUtLUxU/rq6uaqfQSgJnZ2d8+umnmDx58hv/eChpSuIlMA0aNMDnn3+Ojz76SK19586dmD9/PsLDw2VK9u66fv06Dh48mOeItpx/iLKwI8n++usvLFq0CN9//z1cXFzkjvPWSvr6VrlK+nEolUrcu3dP416kBw4cQK9evZCUlCRTsndT2bJlcerUKVlvZk7/MTc3x/nz5zVOH8fExKBWrVp4/PixTMneTT/88AOGDRsGW1tbODg4aIxoc/IElSi9evVCRkYGKleujNKlS8PQ0FBt+8OHD2VKJk1et3gD/ls9vKSMEJX048gdOVEoFKhSpYrG6u1paWn49NNPZUz4bho8eDC2bduGSZMmyR2FABgbG+PevXsahV18fLzaTFkqHnPmzMHcuXMxceJEuaNo4IgdSbZ+/frXbg8MDCymJG+nY8eOMDAwwOrVq/O8xVvz5s3ljqiVkn4c69evhxACgwYNwtKlS2FlZaXaljvrL3dldyo+2dnZ+PDDD/HkyRPUrFlT4w+4knSHGX3g7++P+Ph4/Pbbb6r/R5KTk9GlSxfY2dnp9HIn+sjS0hLnzp3TyQk4LOzonVXS17fKpS/HcfjwYTRt2pSjDzpizpw5mD59OqpWrQp7e3uNU00HDhyQMd27Jy4uDi1atMCDBw9U1zefO3cO9vb22LdvH5ydnWVO+G4ZPHgw6tevr5NnE/gblAokOjoaP/74I6Kjo/H111/Dzs4Oe/bsQYUKFVCjRg2542mlpK9vlUtfjsPCwgJXrlxBzZo1AQC//fYbfvzxR3h4eGDGjBmqRUCpeCxatAhr167FgAED5I5CeLHw9fnz57Fx40ZERkbC1NQUAwcOhL+/v8ZoKhU9Nzc3TJs2DSdPnsxzRFvO5YBY2JFkhw8fRrt27dC0aVMcOXIEc+fOhZ2dHSIjI7FmzRps375d7ohaKenrW+XSl+MYOnQoJk2ahJo1a+LGjRvo1asXunXrhm3btiEjIwNLly6VO+I7xdjYGE2bNpU7Br3EzMwMzZo1Q4UKFVSTpPbs2QMA6NSpk5zR3jmrVq2Cubk5Dh8+jMOHD6ttUygU8q7zWNz3MKOSr1GjRmLRokVCCPV7eoaHhwsnJyc5o0kSGhoqduzYIYQQ4vr166Jq1apCoVAIW1tbERYWJnM67enLcVhaWoqoqCghhBDz5s1T3Uv16NGj4r333pMz2jvpyy+/FKNGjZI7Bv2/6OhoUatWLaFQKIRSqVT9N/dBlIsjdiTZhQsX8Msvv2i029nZ6fy9L1+mL7d405fjEEKo1oLav38/PvzwQwAv1lMrST9X+uLUqVM4cOAA/vjjD9SoUUPjVNPOnTtlSvZuGjNmDCpVqoSwsLA8J0kR5WJhR5JZW1sjPj4elSpVUms/e/YsnJycZEpVOEriLd7yUhKPo169epgzZw58fHxw+PBhrFixAsCLdbrs7e1lTvfusba2Rrdu3eSOQf/vxIkTOHDgAGxtbaFUKmFgYIBmzZohJCQEo0ePLjGTpEqyoKAgzJ49G2ZmZggKCnptXzlnjbOwI8l69+6NiRMnYtu2bVAoFMjJycGxY8cwfvx4BAQEyB2PSqilS5eib9++2LVrF6ZMmQI3NzcAwPbt29GkSROZ0717vvvuO+Tk5Kjue3nz5k3s2rUL1atXVxslpuKhL5OkSrKzZ8/i+fPnqq/zI/eZEi53QpJlZmZixIgRWLduHbKzs1GqVClkZWWhb9++WLduHQwMDOSOSHrk6dOnMDAw4My/Yubr64tu3brh008/RXJyMqpVqwZDQ0Pcv38fixcvxrBhw+SO+E5p3rw5xo0bhy5duqBPnz549OgRpk6dilWrVuHMmTO4ePGi3BEpD3fu3IGjo2Ox3paPhR0V2O3bt3HhwgWkpaXB29sb7u7uckeiEi45ORnbt29HdHQ0JkyYgDJlyiAiIgL29vYl/jR/SWNra4vDhw+jRo0aWL16Nb755hucPXsWO3bswPTp03HlyhW5I75T9u7di/T0dHTr1g1RUVH48MMPce3aNZQtWxZbtmxBq1at5I5IeZBjIWOeiiXJ8rq24OTJk1AoFDAxMYGbmxs6d+5cIq/zIvmcP38erVu3hrW1NW7evIkhQ4agTJky2LlzJ2JjY7Fhwwa5I75TMjIyVKf+/vrrL3Tr1g1KpRKNGjXCrVu3ZE737tGXSVLvGjnGzljYkWRnz55FREQEsrOzUbVqVQDAtWvXYGBggGrVquG7777DuHHjcPToUXh4eMiclkqKoKAgDBw4EAsWLFAVFADQvn179OnTR8Zk7yY3Nzfs2rULXbt2xd69ezF27FgAQGJiIiwtLWVOR0DJnCRFRa/4TvqS3ujcuTN8fHxw9+5dnDlzBmfOnMGdO3fQpk0b+Pv7q259k/sPAZE2/vnnHwwdOlSj3cnJCQkJCTIkerdNnz4d48ePh4uLCxo2bKi6X+9ff/2luqUVEekeXmNHkjk5OWHfvn0ao3GXLl2Cr68v4uLiEBERAV9fX64/Rlqzs7PD3r174e3tDQsLC0RGRsLV1RX79u3DoEGDcPv2bbkjvnMSEhIQHx+P2rVrqy7+PnXqFCwtLVGtWjWZ0xHpvpd/lxUXjtiRZCkpKUhMTNRoT0pKQmpqKoAXa2Dl3vKGSBudOnXCrFmzVMsJKBQKxMbGYuLEiejevbvM6d5NDg4O8Pb2VpvR16BBAxZ1RFqS4/pHFnYkWefOnTFo0CD8+uuvuHPnDu7cuYNff/0VgwcPRpcuXQC8+Ku+SpUq8galEmXRokVIS0uDnZ0dnjx5gpYtW8LNzQ0WFhaYO3eu3PGIiCST46QoT8WSZGlpaRg7diw2bNiArKwsAECpUqUQGBiIJUuWwMzMDOfOnQMAeHl5yReUSqSjR4/i/PnzSEtLQ506deDj4yN3JCKiPEVFRSE6OhotWrSAqakphBBqo3S3b9+Go6Njsa7vysKOCiwtLQ03btwAALi6usLc3FzmREREREXvwYMH6NWrFw4cOACFQoHr16/D1dUVgwYNgo2NDRYtWiRbNi53QgVmbm6OWrVqyR2DSrBly5Zp3Xf06NFFmISISHtjx45FqVKlEBsbi+rVq6vae/XqhaCgIFkLO47YEZFsKlWqpFU/hUKhGh0mIpKbg4MD9u7di9q1a6vNfL1x4wZq1aqFtLQ02bJxxI6IZBMTEyN3BCIiydLT01G6dGmN9ocPH8LY2FiGRP/hrFgi0jlCCFlmkxERaaN58+ZqtzlUKBTIycnBggUL8MEHH8iYjIUdEemQDRs2oGbNmjA1NYWpqSlq1aqFn376Se5YRERqFixYgFWrVqFdu3bIzMzE559/Dk9PTxw5cgTz58+XNRtPxRKRTli8eDGmTZuGkSNHomnTpgBeLH3y6aef4v79+7xFHRHpDE9PT1y7dg3Lly+HhYUF0tLS0K1bN4wYMQLly5eXNRsnTxCRTqhUqRJmzpyJgIAAtfb169djxowZvB6PiHTC8+fP0bZtW6xcuRLu7u5yx9HAU7FEpBPi4+PRpEkTjfYmTZogPj5ehkRERJoMDQ1x/vx5uWPki4UdEekENzc3bN26VaN9y5YtOvlXMRG9u/r164c1a9bIHSNPvMaOiHTCzJkz0atXLxw5ckR1jd2xY8cQFhaWZ8FHRCSXrKwsrF27Fvv370fdunVhZmamtn3x4sUyJeM1dkSkQ86cOYMlS5bgypUrAIDq1atj3Lhx8Pb2ljkZEdF/XrekiUKhwIEDB4oxzSvvz8KOiIiISD/wVCwR6YycnBxERUUhMTEROTk5attatGghUyoiopKDhR0R6YSTJ0+iT58+uHXrlsZdJxQKBbKzs2VKRkSk7oMPPoBCoch3u5ynYlnYEZFO+PTTT1GvXj3s3r0b5cuXf+0vTSIiOXl5eak9f/78Oc6dO4eLFy8iMDBQnlD/j9fYEZFOMDMzQ2RkJNzc3OSOQkRUIDNmzEBaWhoWLlwoWwauY0dEOqFhw4aIioqSOwYRUYH169cPa9eulTUDT8USkWxeXr191KhRGDduHBISElCzZk0YGhqq9a1Vq1ZxxyMikuTEiRMwMTGRNQNPxRKRbJRKJRQKhcZkiVy52zh5goh0Sbdu3dSeCyEQHx+P06dPY9q0aQgODpYpGUfsiEhGMTExckcgIpLMyspK7blSqUTVqlUxa9Ys+Pr6ypTqBY7YEZFOCAkJgb29PQYNGqTWvnbtWiQlJWHixIkyJSMiKjk4eYKIdML333+PatWqabTXqFEDK1eulCEREVHebt++jTt37qienzp1Cp999hlWrVolY6oXWNgRkU5ISEhA+fLlNdrLlSuH+Ph4GRIREeWtT58+OHjwIIAXv7t8fHxw6tQpTJkyBbNmzZI1Gws7ItIJzs7OOHbsmEb7sWPH4OjoKEMiIqK8Xbx4EQ0aNAAAbN26FTVr1sTx48exceNGrFu3TtZsnDxBRDphyJAh+Oyzz/D8+XO0atUKABAWFobPP/8c48aNkzkdEdF/nj9/DmNjYwDA/v370alTJwBAtWrVZD/DwMKOiHTChAkT8ODBAwwfPhyZmZkAABMTE0ycOBGTJ0+WOR0R0X9yr/3t0KED9u3bh9mzZwMA7t69i7Jly8qajbNiiUinpKWl4cqVKzA1NYW7u7vqr2IiIl1x6NAhdO3aFampqQgMDFTdbeKLL77A1atXsXPnTtmysbAjIiIikig7OxupqamwsbFRtd28eROlS5eGnZ2dbLk4eYKIiIhIgidPnuDZs2eqou7WrVtYunQp/v33X1mLOoCFHREREZEknTt3xoYNGwAAycnJaNiwIRYtWoQuXbpgxYoVsmZjYUdEREQkQUREBJo3bw4A2L59O+zt7XHr1i1s2LABy5YtkzUbCzsiIiIiCTIyMmBhYQEA+Ouvv9CtWzcolUo0atQIt27dkjUbCzsiIiIiCdzc3LBr1y7cvn0be/fuha+vLwAgMTERlpaWsmZjYUdEREQkwfTp0zF+/Hi4uLigQYMGaNy4MYAXo3fe3t6yZuNyJ0REREQSJSQkID4+HrVr14ZS+WKc7NSpU7C0tES1atVky8XCjoiIiKgAoqKiEB0djRYtWsDU1BRCCCgUClkz8VQsERERkQQPHjxA69atUaVKFbRv3151f9jBgwfLfm9rFnZEREREEowdOxaGhoaIjY1F6dKlVe29evVCaGiojMmAUrK+OxEREVEJ89dff2Hv3r1477331Nrd3d253AkRERFRSZKenq42Upfr4cOHMDY2liHRf1jYEREREUnQvHlz1S3FAEChUCAnJwcLFizABx98IGMyzoolIiIikuTixYto3bo16tSpgwMHDqBTp064dOkSHj58iGPHjqFy5cqyZWNhR0RERCRRSkoKli9fjsjISKSlpaFOnToYMWIEypcvL2suFnZEREREWnr+/Dnatm2LlStXwt3dXe44GniNHREREZGWDA0Ncf78eblj5IuFHREREZEE/fr1w5o1a+SOkSeuY0dEREQkQVZWFtauXYv9+/ejbt26MDMzU9u+ePFimZKxsCMiIiKS5OLFi6hTpw4A4Nq1a2rb5L5XLCdPEBEREekJXmNHREREVEC3b9/G7du35Y6hwsKOiIiISIKsrCxMmzYNVlZWcHFxgYuLC6ysrDB16lQ8f/5c1my8xo6IiIhIglGjRmHnzp1YsGABGjduDAA4ceIEZsyYgQcPHmDFihWyZeM1dkREREQSWFlZYfPmzWjXrp1a+59//gl/f3+kpKTIlIynYomIiIgkMTY2houLi0Z7pUqVYGRkVPyBXsLCjoiIiEiCkSNHYvbs2Xj27Jmq7dmzZ5g7dy5GjhwpYzKeiiUiIiKSpGvXrggLC4OxsTFq164NAIiMjERmZiZat26t1nfnzp3Fmo2TJ4iIiIgksLa2Rvfu3dXanJ2dZUqjjiN2REREREXg2LFjqFevHoyNjYvtPVnYERERERUBS0tLnDt3Dq6ursX2npw8QURERFQE5Bg7Y2FHREREpCdY2BERERHpCRZ2RERERHqChR0RERFREVAoFMX+nizsiIiIiIqAHJMnuNwJERERkURZWVk4dOgQoqOj0adPH1hYWODu3buwtLSEubm5bLlY2BERERFJcOvWLbRt2xaxsbF49uwZrl27BldXV4wZMwbPnj3DypUrZcvGU7FEREREEowZMwb16tXDo0ePYGpqqmrPvYesnHivWCIiIiIJ/v77bxw/fhxGRkZq7S4uLoiLi5Mp1QscsSMiIiKSICcnB9nZ2Rrtd+7cgYWFhQyJ/sPCjoiIiEgCX19fLF26VPVcoVAgLS0NwcHBaN++vXzBwMkTRERERJLcuXMHfn5+EELg+vXrqFevHq5fvw5bW1scOXIEdnZ2smVjYUdEREQkUVZWFrZs2YLIyEikpaWhTp066Nu3r9pkCjmwsCMiIiLSE7zGjoiIiEiC9evXY/fu3arnn3/+OaytrdGkSRPcunVLxmQs7IiIiIgk+fLLL1WnXE+cOIHly5djwYIFsLW1xdixY2XNxlOxRERERBKULl0aV69eRYUKFTBx4kTEx8djw4YNuHTpEt5//30kJSXJlo0jdkREREQSmJub48GDBwCAv/76C23atAEAmJiY4MmTJ3JG450niIiIiKRo06YNPv74Y3h7e+PatWuqtesuXboEFxcXWbNxxI6IiIhIgm+//RaNGzdGUlISduzYgbJlywIAzpw5A39/f1mz8Ro7IiIiIj3BU7FEREREb3D+/Hmt+9aqVasIk7weR+yIiIiI3kCpVEKhUCC/sil3m0KhQHZ2djGn+w9H7IiIiIjeICYmRu4IWuGIHREREZGe4IgdERERkQQbNmx47faAgIBiSqKJI3ZEREREEtjY2Kg9f/78OTIyMmBkZITSpUvj4cOHMiXjOnZEREREkjx69EjtkZaWhn///RfNmjXDpk2bZM3GETsiIiKiQnD69Gn069cPV69elS0DR+yIiIiICkGpUqVw9+5deTPI+u5EREREJczvv/+u9lwIgfj4eCxfvhxNmzaVKdULPBVLREREJIFSqX7CU6FQoFy5cmjVqhUWLVqE8uXLy5SMhR0RERFRgeXk5ADQLPbkohspiIiIiEqQNWvWwNPTE6ampjA1NYWnpydWr14tdyxeY0dEREQkxfTp07F48WKMGjUKjRs3BgCcOHECY8eORWxsLGbNmiVbNp6KJSIiIpKgXLlyWLZsGfz9/dXaN23ahFGjRuH+/fsyJeOpWCIiIiJJnj9/jnr16mm0161bF1lZWTIk+g8LOyIiIiIJ+vfvjxUrVmi0r1q1Cn379pUh0X94KpaIiIhIglGjRmHDhg1wdnZGo0aNAADh4eGIjY1FQEAADA0NVX0XL15crNlY2BERERFJ8MEHH2jVT6FQ4MCBA0Wc5pX3ZGFHREREpB94jR0RERGRnmBhR0RERKQnWNgRERER6QkWdkRERER6goUdERERkZ5gYUdERESkJ1jYEREREekJFnZEREREeuL/AFY+3/5iN4tpAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_importances(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Після того як ми визначили які ознаки меншне використовуються, видалимо та заново навчимо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_importence = df\n",
    "\n",
    "df_features_importence = df_features_importence.drop([\"gluc\",\"smoke\",\"alco\",\"active\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = df_features_importence.drop('cardio',axis=1)\n",
    "y_features = df_features_importence['cardio']\n",
    "\n",
    "X_features_train, X_features_test,y_features_train, y_features_test = train_test_split(X_features,y_features, test_size=0.1)\n",
    "\n",
    "X_features_train= scaler.fit_transform(X_features_train)\n",
    "X_features_test = scaler.transform(X_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Навчання моделі Logistic Regression\n",
      "Accuracy: 0.73\n",
      "Precision: 0.77\n",
      "F1-score: 0.73\n",
      "Навчання моделі Decision Tree\n",
      "Accuracy: 0.66\n",
      "Precision: 0.77\n",
      "F1-score: 0.73\n",
      "Навчання моделі Random Forest\n",
      "Accuracy: 0.69\n",
      "Precision: 0.77\n",
      "F1-score: 0.73\n",
      "Навчання моделі KNN\n",
      "Accuracy: 0.69\n",
      "Precision: 0.77\n",
      "F1-score: 0.73\n",
      "Навчання моделі Gradient Boosting\n",
      "Accuracy: 0.74\n",
      "Precision: 0.77\n",
      "F1-score: 0.73\n",
      "Навчання моделі XGBoost\n",
      "Accuracy: 0.74\n",
      "Precision: 0.77\n",
      "F1-score: 0.73\n",
      "Навчання моделі AdaBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Heart-Failure\\env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.73\n",
      "Precision: 0.77\n",
      "F1-score: 0.73\n",
      "Навчання моделі Naive Bayes\n",
      "Accuracy: 0.72\n",
      "Precision: 0.77\n",
      "F1-score: 0.73\n",
      "Навчання моделі MLP Neural Network\n",
      "Accuracy: 0.74\n",
      "Precision: 0.77\n",
      "F1-score: 0.73\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    print(f\"Навчання моделі {name}\")\n",
    "\n",
    "    model = model.fit(X_features_train,y_features_train)\n",
    "\n",
    "    y_features_pred = model.predict(X_features_test)\n",
    "\n",
    "    print(f'Accuracy: {np.round(accuracy_score(y_features_test, y_features_pred), 2)}')\n",
    "    print(f'Precision: {np.round(precision_score(y_test,y_pred_test),2)}')\n",
    "    print(f'F1-score: {np.round(f1_score(y_test,y_pred_test),2)}')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV для моделі RadomForestClassifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best features: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best features accuracy on validate: 0.7334501454851892\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=0)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],  # Кількість дере\n",
    "    'max_depth': [None, 10, 20, 30],  # Глибина\n",
    "    'min_samples_split': [2, 5, 10],  # Мінімальна кількість зразків для поділу\n",
    "    'min_samples_leaf': [1, 2, 4]     # Мінімальна кількість зразків у листку\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid,cv=5,scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train,y_train)\n",
    "\n",
    "print(f'Best features: {grid_search.best_params_}')\n",
    "print(f'Best features accuracy on validate: {grid_search.best_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "функція активації, кільксть прихованих шарів MLP, KNN- k, крос валідація для даних, оптимізаця гіпер параметрів, для звичайний потім ансамбиль, крос для ансамбиль"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Використовуємо GridSearchCV для всіх моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=20000, solver='lbfgs', random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"XGBoost\": xgb.XGBClassifier(n_estimators=100, max_depth=5, learning_rate=0.1, random_state=42),\n",
    "    \"AdaBoost\": AdaBoostClassifier(random_state=42),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"MLP Neural Network\": MLPClassifier(max_iter=2000,random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Налаштування моделі: Logistic Regression\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Найкращі параметри для Logistic Regression: {'C': 0.1, 'solver': 'liblinear'}\n",
      "Середній результат (Accuracy): 0.72\n",
      "Precision: 0.73\n",
      "F1 Score: 0.73\n",
      "\n",
      "Налаштування моделі: Decision Tree\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Найкращі параметри для Decision Tree: {'criterion': 'gini', 'max_depth': 5}\n",
      "Середній результат (Accuracy): 0.73\n",
      "Precision: 0.74\n",
      "F1 Score: 0.73\n",
      "\n",
      "Налаштування моделі: Random Forest\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Найкращі параметри для Random Forest: {'max_depth': 10, 'min_samples_split': 5, 'n_estimators': 500}\n",
      "Середній результат (Accuracy): 0.73\n",
      "Precision: 0.74\n",
      "F1 Score: 0.74\n",
      "\n",
      "Налаштування моделі: KNN\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Найкращі параметри для KNN: {'n_neighbors': 9, 'p': 1, 'weights': 'uniform'}\n",
      "Середній результат (Accuracy): 0.71\n",
      "Precision: 0.73\n",
      "F1 Score: 0.73\n",
      "\n",
      "Налаштування моделі: Gradient Boosting\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "Найкращі параметри для Gradient Boosting: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 200}\n",
      "Середній результат (Accuracy): 0.74\n",
      "Precision: 0.74\n",
      "F1 Score: 0.74\n",
      "\n",
      "Налаштування моделі: XGBoost\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Найкращі параметри для XGBoost: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 200}\n",
      "Середній результат (Accuracy): 0.74\n",
      "Precision: 0.74\n",
      "F1 Score: 0.74\n",
      "\n",
      "Налаштування моделі: AdaBoost\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Heart-Failure\\env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найкращі параметри для AdaBoost: {'learning_rate': 1, 'n_estimators': 100}\n",
      "Середній результат (Accuracy): 0.73\n",
      "Precision: 0.74\n",
      "F1 Score: 0.73\n",
      "\n",
      "Налаштування моделі: Naive Bayes\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Найкращі параметри для Naive Bayes: {}\n",
      "Середній результат (Accuracy): 0.71\n",
      "Precision: 0.71\n",
      "F1 Score: 0.70\n",
      "\n",
      "Налаштування моделі: MLP Neural Network\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Найкращі параметри для MLP Neural Network: {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'solver': 'adam'}\n",
      "Середній результат (Accuracy): 0.73\n",
      "Precision: 0.74\n",
      "F1 Score: 0.74\n"
     ]
    }
   ],
   "source": [
    "param_grids = {\n",
    "    \"Logistic Regression\": {'C': [0.01, 0.1, 1, 10], 'solver': ['lbfgs', 'liblinear']},\n",
    "    \"Decision Tree\": {'max_depth': [2, 5, 10, 20], 'criterion': ['gini', 'entropy']},\n",
    "    \"Random Forest\": {'n_estimators': [100, 200, 500], 'max_depth': [5, 10, 20], 'min_samples_split': [2, 5, 10]},\n",
    "    \"KNN\": {'n_neighbors': [3, 5, 7, 9], 'weights': ['uniform', 'distance'], 'p': [1, 2]},\n",
    "    \"Gradient Boosting\": {'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1, 0.2], 'max_depth': [3, 5, 7]},\n",
    "    \"XGBoost\": {'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 7], 'learning_rate': [0.01, 0.1, 0.2]},\n",
    "    \"AdaBoost\": {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 1]},\n",
    "    \"Naive Bayes\": {},\n",
    "    \"MLP Neural Network\": {\n",
    "        'hidden_layer_sizes': [(50,), (100,), (100, 50)], \n",
    "        'activation': ['relu', 'tanh'], \n",
    "        'solver': ['adam', 'sgd'], \n",
    "        'alpha': [0.0001, 0.001, 0.01]\n",
    "    }\n",
    "}\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "best_models = {}\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nНалаштування моделі: {name}\")\n",
    "    param_grid = param_grids.get(name, {})\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid,\n",
    "        cv=kf,\n",
    "        scoring='accuracy',\n",
    "        verbose=1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_models[name] = grid_search.best_estimator_\n",
    "    results[name] = {\n",
    "        \"Best Params\": grid_search.best_params_,\n",
    "        \"Best Score\": grid_search.best_score_\n",
    "    }\n",
    "    \n",
    "    # Predictions and metric calculations\n",
    "    y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    results[name][\"Precision\"] = precision\n",
    "    results[name][\"F1 Score\"] = f1\n",
    "    \n",
    "    print(f\"Найкращі параметри для {name}: {grid_search.best_params_}\")\n",
    "    print(f\"Середній результат (Accuracy): {grid_search.best_score_:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "\n",
    "# print(\"\\nРезультати для всіх моделей:\")\n",
    "# for name, result in results.items():\n",
    "#     print(f\"{name}:\")\n",
    "#     print(f\"  Найкращі параметри: {result['Best Params']}\")\n",
    "#     print(f\"  Найкращий результат: {result['Best Score']:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Використовуємо підбір гіпер-параметрів для моделі яка собою є створений ансамбиль"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Налаштування моделі: Logistic Regression\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Найкращі параметри для Logistic Regression: {'C': 1, 'solver': 'liblinear'}\n",
      "Середній результат: 0.72\n",
      "MAE: 0.28, RMSE: 0.52\n",
      "\n",
      "Налаштування моделі: Decision Tree\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Найкращі параметри для Decision Tree: {'criterion': 'gini', 'max_depth': 5}\n",
      "Середній результат: 0.73\n",
      "MAE: 0.27, RMSE: 0.52\n",
      "\n",
      "Налаштування моделі: Random Forest\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Найкращі параметри для Random Forest: {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Середній результат: 0.73\n",
      "MAE: 0.27, RMSE: 0.52\n",
      "\n",
      "Налаштування моделі: KNN\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Найкращі параметри для KNN: {'n_neighbors': 9, 'p': 1, 'weights': 'uniform'}\n",
      "Середній результат: 0.71\n",
      "MAE: 0.29, RMSE: 0.54\n",
      "\n",
      "Налаштування моделі: Gradient Boosting\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "Найкращі параметри для Gradient Boosting: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
      "Середній результат: 0.74\n",
      "MAE: 0.26, RMSE: 0.51\n",
      "\n",
      "Налаштування моделі: XGBoost\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Найкращі параметри для XGBoost: {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 50}\n",
      "Середній результат: 0.74\n",
      "MAE: 0.26, RMSE: 0.51\n",
      "\n",
      "Налаштування моделі: AdaBoost\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Heart-Failure\\env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "d:\\Heart-Failure\\env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "d:\\Heart-Failure\\env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "d:\\Heart-Failure\\env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "d:\\Heart-Failure\\env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "d:\\Heart-Failure\\env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найкращі параметри для AdaBoost: {'learning_rate': 1, 'n_estimators': 200}\n",
      "Середній результат: 0.73\n",
      "MAE: 0.27, RMSE: 0.52\n",
      "\n",
      "Налаштування моделі: Naive Bayes\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Найкращі параметри для Naive Bayes: {}\n",
      "Середній результат: 0.71\n",
      "MAE: 0.29, RMSE: 0.54\n",
      "\n",
      "Налаштування моделі: MLP Neural Network\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Найкращі параметри для MLP Neural Network: {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50), 'solver': 'adam'}\n",
      "Середній результат: 0.73\n",
      "MAE: 0.27, RMSE: 0.52\n",
      "\n",
      "Результати для всіх моделей:\n",
      "Logistic Regression:\n",
      "  Найкращі параметри: {'C': 1, 'solver': 'liblinear'}\n",
      "  Найкращий результат (accuracy): 0.72\n",
      "  MAE: 0.28, RMSE: 0.52\n",
      "\n",
      "Decision Tree:\n",
      "  Найкращі параметри: {'criterion': 'gini', 'max_depth': 5}\n",
      "  Найкращий результат (accuracy): 0.73\n",
      "  MAE: 0.27, RMSE: 0.52\n",
      "\n",
      "Random Forest:\n",
      "  Найкращі параметри: {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "  Найкращий результат (accuracy): 0.73\n",
      "  MAE: 0.27, RMSE: 0.52\n",
      "\n",
      "KNN:\n",
      "  Найкращі параметри: {'n_neighbors': 9, 'p': 1, 'weights': 'uniform'}\n",
      "  Найкращий результат (accuracy): 0.71\n",
      "  MAE: 0.29, RMSE: 0.54\n",
      "\n",
      "Gradient Boosting:\n",
      "  Найкращі параметри: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
      "  Найкращий результат (accuracy): 0.74\n",
      "  MAE: 0.26, RMSE: 0.51\n",
      "\n",
      "XGBoost:\n",
      "  Найкращі параметри: {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 50}\n",
      "  Найкращий результат (accuracy): 0.74\n",
      "  MAE: 0.26, RMSE: 0.51\n",
      "\n",
      "AdaBoost:\n",
      "  Найкращі параметри: {'learning_rate': 1, 'n_estimators': 200}\n",
      "  Найкращий результат (accuracy): 0.73\n",
      "  MAE: 0.27, RMSE: 0.52\n",
      "\n",
      "Naive Bayes:\n",
      "  Найкращі параметри: {}\n",
      "  Найкращий результат (accuracy): 0.71\n",
      "  MAE: 0.29, RMSE: 0.54\n",
      "\n",
      "MLP Neural Network:\n",
      "  Найкращі параметри: {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50), 'solver': 'adam'}\n",
      "  Найкращий результат (accuracy): 0.73\n",
      "  MAE: 0.27, RMSE: 0.52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grids = {\n",
    "    \"Logistic Regression\": {'C': [0.01, 0.1, 1, 10], 'solver': ['lbfgs', 'liblinear']},\n",
    "    \"Decision Tree\": {'max_depth': [2, 5, 10, 20], 'criterion': ['gini', 'entropy']},\n",
    "    \"Random Forest\": {'n_estimators': [100, 200, 500], 'max_depth': [5, 10, 20], 'min_samples_split': [2, 5, 10]},\n",
    "    \"KNN\": {'n_neighbors': [3, 5, 7, 9], 'weights': ['uniform', 'distance'], 'p': [1, 2]},\n",
    "    \"Gradient Boosting\": {'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1, 0.2], 'max_depth': [3, 5, 7]},\n",
    "    \"XGBoost\": {'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 7], 'learning_rate': [0.01, 0.1, 0.2]},\n",
    "    \"AdaBoost\": {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 1]},\n",
    "    \"Naive Bayes\": {},\n",
    "    \"MLP Neural Network\": {\n",
    "        'hidden_layer_sizes': [(50,), (100,), (100, 50)], \n",
    "        'activation': ['relu', 'tanh'], \n",
    "        'solver': ['adam', 'sgd'], \n",
    "        'alpha': [0.0001, 0.001, 0.01]\n",
    "    }\n",
    "}\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "best_models = {}\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nНалаштування моделі: {name}\")\n",
    "    param_grid = param_grids.get(name, {})\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid,\n",
    "        cv=kf,\n",
    "        scoring='accuracy',\n",
    "        verbose=1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X, y)\n",
    "    \n",
    "    best_models[name] = grid_search.best_estimator_\n",
    "    results[name] = {\n",
    "        \"Best Params\": grid_search.best_params_,\n",
    "        \"Best Score\": grid_search.best_score_\n",
    "    }\n",
    "    \n",
    "    maes, rmses = [], []\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "        \n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_model.fit(X_train, y_train)\n",
    "        y_pred = best_model.predict(X_val)\n",
    "        \n",
    "        mae = mean_absolute_error(y_val, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "        maes.append(mae)\n",
    "        rmses.append(rmse)\n",
    "    \n",
    "    results[name][\"MAE\"] = np.mean(maes)\n",
    "    results[name][\"RMSE\"] = np.mean(rmses)\n",
    "    \n",
    "    print(f\"Найкращі параметри для {name}: {grid_search.best_params_}\")\n",
    "    print(f\"Середній результат: {grid_search.best_score_:.2f}\")\n",
    "    print(f\"MAE: {np.mean(maes):.2f}, RMSE: {np.mean(rmses):.2f}\")\n",
    "\n",
    "print(\"\\nРезультати для всіх моделей:\")\n",
    "for name, result in results.items():\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Найкращі параметри: {result['Best Params']}\")\n",
    "    print(f\"  Найкращий результат (accuracy): {result['Best Score']:.2f}\")\n",
    "    print(f\"  MAE: {result['MAE']:.2f}, RMSE: {result['RMSE']:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "точність всіх краще і для ансамблиь точність"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Налаштування моделі: Gradient Boosting\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "Найкращі параметри для Gradient Boosting: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
      "Середній результат: 0.74\n",
      "MAE: 0.26, RMSE: 0.51\n",
      "\n",
      "Налаштування моделі: XGBoost\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Найкращі параметри для XGBoost: {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 50}\n",
      "Середній результат: 0.74\n",
      "MAE: 0.26, RMSE: 0.51\n",
      "\n",
      "Результати для всіх моделей:\n",
      "Gradient Boosting:\n",
      "  Найкращі параметри: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
      "  Найкращий результат (accuracy): 0.74\n",
      "  MAE: 0.26, RMSE: 0.51\n",
      "\n",
      "XGBoost:\n",
      "  Найкращі параметри: {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 50}\n",
      "  Найкращий результат (accuracy): 0.74\n",
      "  MAE: 0.26, RMSE: 0.51\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_gridss = {\n",
    "    \"Gradient Boosting\": {'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1, 0.2], 'max_depth': [3, 5, 7]},\n",
    "    \"XGBoost\": {'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 7], 'learning_rate': [0.01, 0.1, 0.2]},\n",
    "}\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "best_models = {}\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nНалаштування моделі: {name}\")\n",
    "    param_grid = param_gridss.get(name, {})\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid,\n",
    "        cv=kf,\n",
    "        scoring='accuracy',\n",
    "        verbose=1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X, y)\n",
    "    \n",
    "    best_models[name] = grid_search.best_estimator_\n",
    "    results[name] = {\n",
    "        \"Best Params\": grid_search.best_params_,\n",
    "        \"Best Score\": grid_search.best_score_\n",
    "    }\n",
    "    \n",
    "    maes, rmses = [], []\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "        \n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_model.fit(X_train, y_train)\n",
    "        y_pred = best_model.predict(X_val)\n",
    "        \n",
    "        mae = mean_absolute_error(y_val, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "        maes.append(mae)\n",
    "        rmses.append(rmse)\n",
    "    \n",
    "    results[name][\"MAE\"] = np.mean(maes)\n",
    "    results[name][\"RMSE\"] = np.mean(rmses)\n",
    "    \n",
    "    print(f\"Найкращі параметри для {name}: {grid_search.best_params_}\")\n",
    "    print(f\"Середній результат: {grid_search.best_score_:.2f}\")\n",
    "    print(f\"MAE: {np.mean(maes):.2f}, RMSE: {np.mean(rmses):.2f}\")\n",
    "\n",
    "print(\"\\nРезультати для всіх моделей:\")\n",
    "for name, result in results.items():\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Найкращі параметри: {result['Best Params']}\")\n",
    "    print(f\"  Найкращий результат (accuracy): {result['Best Score']:.2f}\")\n",
    "    print(f\"  MAE: {result['MAE']:.2f}, RMSE: {result['RMSE']:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Навчаємо модель Logistic Regression з використанням K-Fold\n",
      "Точність для кожного фолду: [0.7225991649269311, 0.7190327070285316, 0.7294711203897007, 0.7172929714683368, 0.7247738343771747, 0.7305785123966942]\n",
      "Середня точність: 0.72\n",
      "\n",
      "Навчаємо модель Random Forest з використанням K-Fold\n",
      "Точність для кожного фолду: [0.6934585942936674, 0.6948503827418232, 0.706767571329158, 0.6898921363952679, 0.6984168406402227, 0.6989125706829056]\n",
      "Середня точність: 0.70\n",
      "\n",
      "Навчаємо модель KNN з використанням K-Fold\n",
      "Точність для кожного фолду: [0.6916318719554627, 0.6959812108559499, 0.6987647877522617, 0.6875434933890049, 0.691196938065414, 0.7004784688995215]\n",
      "Середня точність: 0.69\n",
      "\n",
      "Навчаємо модель MLP Neural Network з використанням K-Fold\n",
      "Точність для кожного фолду: [0.7305149617258176, 0.7233820459290188, 0.7254697286012526, 0.7086812804453723, 0.7286012526096033, 0.7307525010874293]\n",
      "Середня точність: 0.72\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "for name,model in models.items():\n",
    "    print(f'Навчаємо модель {name} з використанням K-Fold')\n",
    "    accuracy_scores = []\n",
    "    kf = KFold(n_splits=6, shuffle=True, random_state=42)\n",
    "\n",
    "    for train_index,test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        model.fit(X_train,y_train)\n",
    "\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        \n",
    "        accuracy_scores.append(accuracy_score(y_test,y_pred_test))\n",
    "\n",
    "    print(f\"Точність для кожного фолду: {accuracy_scores}\")\n",
    "    print(f\"Середня точність: {np.mean(accuracy_scores):.2f}\\n\")\n",
    "\n",
    "    accuracy_scores.clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Налаштування моделі: Gradient Boosting\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Найкращі параметри для Gradient Boosting: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
      "Середній результат: 0.73\n",
      "\n",
      "Налаштування моделі: XGBoost\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Найкращі параметри для XGBoost: {}\n",
      "Середній результат: 0.73\n",
      "\n",
      "Результати для всіх моделей:\n",
      "Gradient Boosting:\n",
      "  Найкращі параметри: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
      "  Найкращий результат: 0.73\n",
      "\n",
      "XGBoost:\n",
      "  Найкращі параметри: {}\n",
      "  Найкращий результат: 0.73\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "param_grids = {\n",
    "    # \"Logistic Regression\": {'C': [0.01, 0.1, 1, 10], 'solver': ['lbfgs', 'liblinear']},\n",
    "    # \"Decision Tree\": {'max_depth': [None, 5, 10, 20], 'criterion': ['gini', 'entropy']},\n",
    "    # \"Random Forest\": {'n_estimators': [100, 200, 500], 'max_depth': [None, 10, 20], 'min_samples_split': [2, 5, 10]},\n",
    "    # \"KNN\": {'n_neighbors': [5, 8, 10, 12], 'weights': ['uniform', 'distance'], 'p': [1, 2]},\n",
    "    \"Gradient Boosting\": {'n_estimators': [200], 'learning_rate': [0.1], 'max_depth': [5]},\n",
    "    # \"XGBoost\": {'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 7], 'learning_rate': [0.01, 0.1, 0.2]},\n",
    "    # \"AdaBoost\": {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 0.001]},\n",
    "    # \"Naive Bayes\": {},\n",
    "    # \"MLP Neural Network\": {\n",
    "    #     'hidden_layer_sizes': [(50,), (100,), (100, 50)], \n",
    "    #     'activation': ['relu', 'tanh'], \n",
    "    #     'solver': ['adam', 'sgd'], \n",
    "    #     'alpha': [0.0001, 0.001, 0.01]\n",
    "    # }\n",
    "}\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "best_models = {}\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nНалаштування моделі: {name}\")\n",
    "    param_grid = param_grids.get(name, {})\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid,\n",
    "        cv=kf,\n",
    "        scoring='accuracy',\n",
    "        verbose=1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    joblib.dump(grid_search.best_estimator_, f'{name}_model_predict.pkl')\n",
    "    \n",
    "    best_models[name] = grid_search.best_estimator_\n",
    "    results[name] = {\n",
    "        \"Best Params\": grid_search.best_params_,\n",
    "        \"Best Score\": grid_search.best_score_\n",
    "    }\n",
    "    print(f\"Найкращі параметри для {name}: {grid_search.best_params_}\")\n",
    "    print(f\"Середній результат: {grid_search.best_score_:.2f}\")\n",
    "\n",
    "print(\"\\nРезультати для всіх моделей:\")\n",
    "for name, result in results.items():\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Найкращі параметри: {result['Best Params']}\")\n",
    "    print(f\"  Найкращий результат: {result['Best Score']:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
